{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrV21bF8yUQL",
        "outputId": "bd9e18c0-358b-49ad-9bf7-11c7c05d947b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ ローカル環境で実行中です\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: 環境設定とセットアップ\n",
        "\"\"\"\n",
        "LA-Bench 2025: 実験手順生成タスク\n",
        "Baseline Implementation for Google Colaboratory\n",
        "GitHub: https://github.com/lasa-or-jp/la-bench.git\n",
        "\"\"\"\n",
        "\n",
        "#@title 1. 環境セットアップ { display-mode: \"form\" }\n",
        "#@markdown このセルを実行して必要なライブラリをインストールし、リポジトリをクローンします。\n",
        "\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Colabかどうかの確認\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"✅ Google Colaboratory環境を検出しました\")\n",
        "    # 必要なライブラリのインストール\n",
        "    print(\"\\n📦 必要なライブラリをインストール中...\")\n",
        "    !pip install -q openai pyyaml tqdm pandas\n",
        "\n",
        "    print(\"✅ ライブラリのインストール完了\")\n",
        "\n",
        "    # GitHubリポジトリのクローン\n",
        "    REPO_URL = \"https://github.com/lasa-or-jp/la-bench.git\"\n",
        "    REPO_NAME = \"la-bench\"\n",
        "\n",
        "    if not os.path.exists(REPO_NAME):\n",
        "        print(f\"\\n📥 リポジトリをクローン中: {REPO_URL}\")\n",
        "        !git clone -q {REPO_URL}\n",
        "        print(f\"✅ リポジトリのクローン完了: {REPO_NAME}/\")\n",
        "    else:\n",
        "        print(f\"\\n📂 リポジトリは既に存在します: {REPO_NAME}/\")\n",
        "        print(\"📥 最新版に更新中...\")\n",
        "        !cd {REPO_NAME} && git pull -q\n",
        "        print(\"✅ 更新完了\")\n",
        "\n",
        "    # 作業ディレクトリの設定\n",
        "    WORK_DIR = Path(REPO_NAME)\n",
        "    os.chdir(WORK_DIR)\n",
        "    print(f\"\\n📍 作業ディレクトリ: {os.getcwd()}\")\n",
        "\n",
        "    # ディレクトリ構造の確認\n",
        "    print(\"\\n📊 プロジェクト構造:\")\n",
        "    !ls -la\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"⚠️ ローカル環境で実行中です\")\n",
        "    if Path.cwd().name == \"notebooks\":\n",
        "        os.chdir(Path.cwd().parent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PZr_6rXsyqlK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔑 APIキー: ********************LdwA\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: OpenAI APIキーの設定\n",
        "#@title 2. OpenAI API Key設定 { display-mode: \"form\" }\n",
        "#@markdown OpenAI APIキーを入力してください。キーは安全に管理されます。\n",
        "\n",
        "\n",
        "# APIキーの取得方法を選択\n",
        "use_secrets = True  #@param {type:\"boolean\"}\n",
        "#@markdown ☝️ Google Colab Secretsを使用する場合はチェック\n",
        "\n",
        "if IN_COLAB:\n",
        "    import getpass\n",
        "    from google.colab import userdata\n",
        "    if use_secrets:\n",
        "        try:\n",
        "            # Colab Secretsから取得\n",
        "            API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "            print(\"✅ APIキーをSecretsから取得しました\")\n",
        "        except Exception as e:\n",
        "            print(\"⚠️ Secretsからの取得に失敗しました\")\n",
        "            print(\"左側のパネルの🔑アイコンから'OPENAI_API_KEY'を設定してください\")\n",
        "            API_KEY = None\n",
        "    else:\n",
        "        # 直接入力\n",
        "        api_key_input = getpass.getpass(\"🔑 OpenAI API Keyを入力: \")\n",
        "        if api_key_input:\n",
        "            API_KEY = api_key_input\n",
        "            os.environ['OPENAI_API_KEY'] = API_KEY\n",
        "            print(\"✅ APIキーが設定されました\")\n",
        "        else:\n",
        "            API_KEY = None\n",
        "            print(\"⚠️ APIキーが設定されていません（ヒューリスティック手法のみ使用）\")\n",
        "else:\n",
        "    # ローカル環境の場合\n",
        "    API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "    if not API_KEY:\n",
        "        API_KEY = input(\"OpenAI API Key: \")\n",
        "\n",
        "# APIキーの検証\n",
        "if API_KEY:\n",
        "    print(f\"🔑 APIキー: {'*' * 20}{API_KEY[-4:]}\")\n",
        "else:\n",
        "    print(\"⚠️ GPT機能は使用できません\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "71dPwmdnzEfP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "LA-Bench 2025 Baseline Implementation\n",
            "実行環境: Local\n",
            "実行時刻: 2025-09-11 01:22:52\n",
            "OpenAI利用可能: True\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: ライブラリのインポートと設定\n",
        "#@title 3. ライブラリのインポート { display-mode: \"form\" }\n",
        "\n",
        "import json\n",
        "import yaml\n",
        "import time\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Optional, Tuple, Set, Any\n",
        "from pathlib import Path\n",
        "from copy import deepcopy\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# データ処理\n",
        "import pandas as pd\n",
        "from dataclasses import dataclass, field\n",
        "\n",
        "# OpenAI API\n",
        "try:\n",
        "    from openai import OpenAI\n",
        "    OPENAI_AVAILABLE = True\n",
        "except ImportError:\n",
        "    OPENAI_AVAILABLE = False\n",
        "    print(\"⚠️ OpenAIライブラリが利用できません\")\n",
        "\n",
        "# プログレスバー (Colab対応)\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# ログ設定\n",
        "import logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    datefmt='%H:%M:%S'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"LA-Bench 2025 Baseline Implementation\")\n",
        "print(f\"実行環境: {'Google Colab' if IN_COLAB else 'Local'}\")\n",
        "print(f\"実行時刻: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"OpenAI利用可能: {OPENAI_AVAILABLE and API_KEY is not None}\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0rypmgB20Yc2"
      },
      "outputs": [],
      "source": [
        "# Cell 4: データ構造\n",
        "#@title 4. データ構造の定義 { display-mode: \"form\" }\n",
        "\n",
        "@dataclass\n",
        "class Step:\n",
        "    id: int\n",
        "    text: str\n",
        "\n",
        "@dataclass\n",
        "class ExampleInput:\n",
        "    instruction: str\n",
        "    mandatory_objects: Set[str] = field(default_factory=set)\n",
        "    source_protocol_steps: List[Step] = field(default_factory=list)\n",
        "    expected_final_states: Set[str] = field(default_factory=set)\n",
        "    references: List[str] = field(default_factory=list)\n",
        "\n",
        "@dataclass\n",
        "class ExampleOutput:\n",
        "    procedure_steps: List[Step] = field(default_factory=list)\n",
        "\n",
        "@dataclass\n",
        "class Measurement:\n",
        "    specific_criteria: Dict[str, int] = field(default_factory=dict)\n",
        "\n",
        "@dataclass\n",
        "class ExampleSample:\n",
        "    id: str\n",
        "    input: ExampleInput\n",
        "    output: ExampleOutput\n",
        "    measurement: Optional[Measurement] = None\n",
        "\n",
        "def _to_set(x):\n",
        "    return set(x) if isinstance(x, (list, set, tuple)) else set()\n",
        "\n",
        "def _to_list(x):\n",
        "    return list(x) if isinstance(x, (list, set, tuple)) else (x if isinstance(x, list) else [])\n",
        "\n",
        "def _to_steps(x) -> List[Step]:\n",
        "    steps: List[Step] = []\n",
        "    arr = _to_list(x)\n",
        "    if not arr:\n",
        "        return steps\n",
        "    if isinstance(arr[0], dict):\n",
        "        for it in arr:\n",
        "            try:\n",
        "                sid = int(it.get(\"id\", len(steps) + 1))\n",
        "            except Exception:\n",
        "                sid = len(steps) + 1\n",
        "            steps.append(Step(id=sid, text=str(it.get(\"text\", \"\")).strip()))\n",
        "    else:\n",
        "        for idx, s in enumerate(arr, start=1):\n",
        "            steps.append(Step(id=idx, text=str(s).strip()))\n",
        "    return steps\n",
        "\n",
        "def parse_sample(obj: Dict[str, Any]) -> ExampleSample:\n",
        "    sid = obj.get(\"id\") or obj.get(\"sample_id\") or \"unknown\"\n",
        "    i = obj.get(\"input\", {})\n",
        "    o = obj.get(\"output\", {})\n",
        "    m = obj.get(\"measurement\", {})\n",
        "\n",
        "    # Measurement.specific_criteria を dict に正規化（list形式も許容）\n",
        "    sc_raw = m.get(\"specific_criteria\", {})\n",
        "    sc: Dict[str, int] = {}\n",
        "    if isinstance(sc_raw, dict):\n",
        "        for k, v in sc_raw.items():\n",
        "            try:\n",
        "                sc[str(k)] = int(v)\n",
        "            except Exception:\n",
        "                pass\n",
        "    elif isinstance(sc_raw, list):\n",
        "        for it in sc_raw:\n",
        "            try:\n",
        "                k = it.get(\"item\")\n",
        "                v = int(it.get(\"score\", 0))\n",
        "                if k:\n",
        "                    sc[str(k)] = v\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    sample = ExampleSample(\n",
        "        id=str(sid),\n",
        "        input=ExampleInput(\n",
        "            instruction=str(i.get(\"instruction\", \"\")).strip(),\n",
        "            mandatory_objects=_to_set(i.get(\"mandatory_objects\", [])),\n",
        "            source_protocol_steps=_to_steps(i.get(\"source_protocol_steps\", [])),\n",
        "            expected_final_states=_to_set(i.get(\"expected_final_states\", [])),\n",
        "            references=_to_list(i.get(\"references\", [])),\n",
        "        ),\n",
        "        output=ExampleOutput(\n",
        "            procedure_steps=_to_steps(o.get(\"procedure_steps\", []))\n",
        "        ),\n",
        "        measurement=Measurement(specific_criteria=sc) if sc else None\n",
        "    )\n",
        "    return sample\n",
        "\n",
        "def load_example_jsonl(path: str):\n",
        "    samples = []\n",
        "    p = Path(path)\n",
        "    if not p.exists():\n",
        "        raise FileNotFoundError(f\"JSONL not found: {p}\")\n",
        "    for line in p.read_text(encoding=\"utf-8\").splitlines():\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        try:\n",
        "            obj = json.loads(line)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ JSONL parse error: {e}\")\n",
        "            continue\n",
        "        samples.append(parse_sample(obj))\n",
        "    return samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MXF0Ou0B6sFB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Loaded 5 samples from data/example/example.jsonl\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: JSONLローダーの利用\n",
        "#@title 5. JSONLファイルを読み込む { display-mode: \"form\" }\n",
        "\n",
        "jsonl_path = 'data/example/example.jsonl'  #@param {type:'string'}\n",
        "try:\n",
        "    samples = load_example_jsonl(jsonl_path)\n",
        "    print(f'✅ Loaded {len(samples)} samples from {jsonl_path}')\n",
        "except Exception as e:\n",
        "    print(f'❌ Load error: {e}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WZ94EpzOInJr"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "01:23:04 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "01:23:19 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "01:23:25 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "01:23:39 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "01:23:53 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 生成完了: 5 samples\n",
            "例: sample_1 → 10 steps\n",
            "📄 Saved JSONL: outputs/runs/generated_20250911_012353.jsonl\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<a href='/Users/kato/Dropbox/Programs/gensurv/la-bench/outputs/runs/generated_20250911_012353.jsonl' target='_blank'>/Users/kato/Dropbox/Programs/gensurv/la-bench/outputs/runs/generated_20250911_012353.jsonl</a><br>"
            ],
            "text/plain": [
              "/Users/kato/Dropbox/Programs/gensurv/la-bench/outputs/runs/generated_20250911_012353.jsonl"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Cell 6: 実験手順の生成（OpenAI, Pydantic構造化）\n",
        "#@title 6. LLMで Input から Output（procedure_steps）を生成 { display-mode: \"form\" }\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# モデル設定\n",
        "MODEL_NAME = \"gpt-4.1-mini-2025-04-14\" #@param [\"gpt-4.1-mini-2025-04-14\", \"gpt-4o-2024-08-06\", \"gpt-5-2025-08-07\", \"gpt-5-mini-2025-08-07\", \"gpt-5-nano-2025-08-07\"]\n",
        "#@markdown gpt-4o-mini, gpt-4o-2024-08-06, あるいはそれ以降のモデルに対応しています。<br>\n",
        "#@markdown (Structured outputを使用しているため) <br>\n",
        "#@markdown gpt-5系モデルを使用する場合、temperature=1.0としてください。\n",
        "TEMPERATURE = 0.7 # @param\n",
        "\n",
        "#@markdown `build_messages`関数において、LLMの入力を設計しています。\n",
        "\n",
        "class StepModel(BaseModel):\n",
        "    id: int = Field(ge=1, description=\"ステップ番号\")\n",
        "    text: str = Field(description=\"実験手順の詳細な説明\")\n",
        "\n",
        "class GeneratedOutput(BaseModel):\n",
        "    procedure_steps: List[StepModel] = Field(\n",
        "        description=\"実験手順のリスト\",\n",
        "        min_items=1,\n",
        "        max_items=50\n",
        "    )\n",
        "\n",
        "def build_messages(sample: ExampleSample) -> list[dict]:\n",
        "    sys = (\n",
        "        \"あなたは生命科学実験の専門家です。以下の Input を読み、\"\n",
        "        \"日本語で実行可能な実験手順（procedure_steps）を返してください。\"\n",
        "        \"制約: ステップ数は最大50、各ステップは10文以下、idは1から昇順。\"\n",
        "    )\n",
        "    user_lines = []\n",
        "    user_lines.append(f\"【実験指示】\\n{sample.input.instruction}\")\n",
        "    if sample.input.mandatory_objects:\n",
        "        user_lines.append(\"\\n【使用する物品】\")\n",
        "        for it in sorted(sample.input.mandatory_objects):\n",
        "            user_lines.append(f\"- {it}\")\n",
        "    if sample.input.source_protocol_steps:\n",
        "        user_lines.append(\"\\n【元プロトコルの手順（参考）】\")\n",
        "        for st in sample.input.source_protocol_steps:\n",
        "            user_lines.append(f\"- {st.id}. {st.text}\")\n",
        "    if sample.input.expected_final_states:\n",
        "        user_lines.append(\"\\n【期待される最終状態】\")\n",
        "        for fs in sorted(sample.input.expected_final_states):\n",
        "            user_lines.append(f\"- {fs}\")\n",
        "    if sample.input.references:\n",
        "        user_lines.append(\"\\n【参考文献URL】\")\n",
        "        for ref in sample.input.references:\n",
        "            user_lines.append(f\"- {ref}\")\n",
        "    usr = \"\\n\".join(user_lines)\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": sys},\n",
        "        {\"role\": \"user\", \"content\": usr},\n",
        "    ]\n",
        "\n",
        "def generate_outputs(samples: list[ExampleSample]) -> list[dict]:\n",
        "    client = OpenAI(api_key=API_KEY)\n",
        "    results: list[dict] = []\n",
        "    for sm in samples:\n",
        "        msgs = build_messages(sm)\n",
        "        try:\n",
        "            completion = client.chat.completions.parse(\n",
        "                model=MODEL_NAME,\n",
        "                messages=msgs,\n",
        "                temperature=TEMPERATURE,\n",
        "                response_format=GeneratedOutput,\n",
        "            )\n",
        "            parsed: GeneratedOutput = completion.choices[0].message.parsed  # type: ignore\n",
        "            steps = [\n",
        "                Step(id=s.id, text=s.text)\n",
        "                for s in sorted(parsed.procedure_steps, key=lambda x: x.id)\n",
        "            ][:50]\n",
        "        except Exception as e:\n",
        "            print(f\"❌ 生成失敗: {sm.id}: {e}\")\n",
        "            steps = []  # no fallback\n",
        "        results.append({\n",
        "            \"id\": sm.id,\n",
        "            \"procedure_steps\": [{\"id\": s.id, \"text\": s.text} for s in steps],\n",
        "        })\n",
        "    print(f\"✅ 生成完了: {len(results)} samples\")\n",
        "    return results\n",
        "\n",
        "# 実行\n",
        "generated_results = generate_outputs(samples)\n",
        "if generated_results:\n",
        "    print(f\"例: {generated_results[0]['id']} → {len(generated_results[0]['procedure_steps'])} steps\")\n",
        "\n",
        "# 生成結果を JSONL で保存し、ダウンロードリンクを表示\n",
        "ts = time.strftime('%Y%m%d_%H%M%S')\n",
        "out_dir = Path('./outputs/runs')\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "jsonl_path = out_dir / f'generated_{ts}.jsonl'\n",
        "with jsonl_path.open('w', encoding='utf-8') as f:\n",
        "    for rec in generated_results:\n",
        "        obj = {\"id\": rec[\"id\"], \"output\": {\"procedure_steps\": rec[\"procedure_steps\"]}}\n",
        "        line = json.dumps(obj, ensure_ascii=False, separators=(\",\", \":\"))\n",
        "        f.write(line + \"\\n\")\n",
        "print(f\"📄 Saved JSONL: {jsonl_path}\")\n",
        "\n",
        "# ダウンロード（Colab/ローカル双方に対応）\n",
        "try:\n",
        "    from google.colab import files as colab_files  # type: ignore\n",
        "    # ダウンロード確認ダイアログを出して、yならダウンロード\n",
        "    from google.colab.output import eval_js\n",
        "    print(f\"Download file: {jsonl_path}\")\n",
        "    confirm = eval_js('confirm(\"生成されたJSONLファイルをダウンロードしますか？\")')\n",
        "    if confirm:\n",
        "      colab_files.download(str(jsonl_path))\n",
        "    else:\n",
        "      print(\"ダウンロードをスキップしました。\")\n",
        "\n",
        "except Exception:\n",
        "    from IPython.display import FileLink, display\n",
        "    display(FileLink(str(jsonl_path.resolve())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wYtMf3bJOzcN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "01:24:04 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "01:24:09 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "01:24:17 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "01:24:21 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "01:24:30 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ LLM-as-a-judge: Scored 5 samples (0-10)\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "id",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "general_score",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "specific_score",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "total_score",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "ref": "2a363cc5-831e-4fed-8f6d-c5ca8278cec7",
              "rows": [
                [
                  "0",
                  "sample_1",
                  "5.0",
                  "4.0",
                  "9.0"
                ],
                [
                  "1",
                  "sample_2",
                  "5.0",
                  "3.0",
                  "8.0"
                ],
                [
                  "2",
                  "sample_3",
                  "5.0",
                  "3.0",
                  "8.0"
                ],
                [
                  "3",
                  "sample_4",
                  "5.0",
                  "3.0",
                  "8.0"
                ],
                [
                  "4",
                  "sample_5",
                  "5.0",
                  "3.0",
                  "8.0"
                ]
              ],
              "shape": {
                "columns": 4,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>general_score</th>\n",
              "      <th>specific_score</th>\n",
              "      <th>total_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sample_1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sample_2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sample_3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sample_4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sample_5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  general_score  specific_score  total_score\n",
              "0  sample_1            5.0             4.0          9.0\n",
              "1  sample_2            5.0             3.0          8.0\n",
              "2  sample_3            5.0             3.0          8.0\n",
              "3  sample_4            5.0             3.0          8.0\n",
              "4  sample_5            5.0             3.0          8.0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📄 Saved: outputs/runs/eval_llm_20250911_012353.csv\n",
            "Download file: outputs/runs/eval_llm_20250911_012353.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<a href='/Users/kato/Dropbox/Programs/gensurv/la-bench/outputs/runs/eval_llm_20250911_012353.csv' target='_blank'>/Users/kato/Dropbox/Programs/gensurv/la-bench/outputs/runs/eval_llm_20250911_012353.csv</a><br>"
            ],
            "text/plain": [
              "/Users/kato/Dropbox/Programs/gensurv/la-bench/outputs/runs/eval_llm_20250911_012353.csv"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Cell 7: LLM-as-a-judge 評価（10点満点）\n",
        "#@title 7. LLM で共通5点 + 個別5点を採点 { display-mode: \"form\" }\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "from typing import List, Optional\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "try:\n",
        "    from openai import OpenAI\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\"OpenAI SDK v1 が見つかりません。`uv add openai` で追加してください。\") from e\n",
        "\n",
        "JUDGE_MODEL = \"gpt-4.1-mini\"  # 高性能推奨モデルに変更可\n",
        "JUDGE_TEMPERATURE = 0.2\n",
        "\n",
        "class JudgeOutput(BaseModel):\n",
        "    general_score: float = Field(ge=0, le=5)\n",
        "    specific_score: float = Field(ge=0, le=5)\n",
        "    final_score: float = Field(ge=0, le=10)\n",
        "    general_reason: str\n",
        "    specific_matches: List[str] = []\n",
        "    notes: Optional[str] = None\n",
        "\n",
        "def build_judge_messages(sample: ExampleSample, steps: List[Step]) -> list[dict]:\n",
        "    # 評価基準（共通5点 + 個別5点）\n",
        "    system = (\n",
        "        \"あなたは生命科学実験の専門家であり、公平な採点者です。\"\n",
        "        \"以下の基準に従って、与えられた Input と生成手順（Output）を評価し、\"\n",
        "        \"general_score(0-5) と specific_score(0-5) と final_score(0-10) を出力してください。\"\n",
        "        \"\\n\\n[共通採点基準 5点満点]\\n\"\n",
        "        \"加点(+1ずつ): 1) 実験指示のパラメータ反映, 2) 使用する物品の反映, 3) 元手順の論理反映, 4) 期待される最終状態の達成, 5) 適切な補完。\\n\"\n",
        "        \"減点: 不自然な日本語/ハルシネーション, 計算ミス, 手順矛盾。\\n\"\n",
        "        \"上限: 入力手順の丸写し等の過度の安全性が見られる場合、general_score は最大2点に制限。\\n\\n\"\n",
        "        \"[個別採点基準 5点満点]\\n\"\n",
        "        \"与えられた specific_criteria の各 item が手順に含まれる/満たすなら、その score を加点（合計5点で上限）。\"\n",
        "    )\n",
        "\n",
        "    parts = []\n",
        "    parts.append(f\"【実験指示】\\n{sample.input.instruction}\")\n",
        "    if sample.input.mandatory_objects:\n",
        "        parts.append(\"\\n【使用する物品】\")\n",
        "        for it in sorted(sample.input.mandatory_objects):\n",
        "            parts.append(f\"- {it}\")\n",
        "    if sample.input.source_protocol_steps:\n",
        "        parts.append(\"\\n【元プロトコルの手順（参考）】\")\n",
        "        for st in sample.input.source_protocol_steps:\n",
        "            parts.append(f\"- {st.id}. {st.text}\")\n",
        "    if sample.input.expected_final_states:\n",
        "        parts.append(\"\\n【期待される最終状態】\")\n",
        "        for fs in sorted(sample.input.expected_final_states):\n",
        "            parts.append(f\"- {fs}\")\n",
        "    if sample.input.references:\n",
        "        parts.append(\"\\n【参考文献】\")\n",
        "        for ref in sample.input.references:\n",
        "            parts.append(f\"- {ref}\")\n",
        "\n",
        "    parts.append(\"\\n【生成手順（Output）】\")\n",
        "    for s in steps:\n",
        "        parts.append(f\"- {s.id}. {s.text}\")\n",
        "\n",
        "    parts.append(\"\\n【specific_criteria】\")\n",
        "    if sample.measurement and sample.measurement.specific_criteria:\n",
        "        for item, sc in sample.measurement.specific_criteria.items():\n",
        "            parts.append(f\"- ({int(sc)}点) {item}\")\n",
        "    else:\n",
        "        parts.append(\"- なし\")\n",
        "\n",
        "    user = \"\\n\".join(parts)\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": user},\n",
        "    ]\n",
        "\n",
        "def judge_with_llm(samples: List[ExampleSample], generated: list[dict]) -> pd.DataFrame:\n",
        "    client = OpenAI(api_key=API_KEY) if 'API_KEY' in globals() and API_KEY else OpenAI()\n",
        "    proc_map = {g['id']: [Step(id=it['id'], text=it['text']) for it in g['procedure_steps']] for g in generated}\n",
        "    rows = []\n",
        "    quota_exhausted = False\n",
        "    def _is_insufficient_quota(err: Exception) -> bool:\n",
        "        s = str(err)\n",
        "        return 'insufficient_quota' in s or 'You exceeded your current quota' in s\n",
        "    for sm in samples:\n",
        "        if quota_exhausted:\n",
        "            print(f\"⏭️ スキップ採点: {sm.id}（クォータ不足）\")\n",
        "            rows.append({\n",
        "                'id': sm.id,\n",
        "                'general_score': 0.0,\n",
        "                'specific_score': 0.0,\n",
        "                'total_score': 0.0,\n",
        "                'notes': 'skipped_due_to_quota',\n",
        "            })\n",
        "            continue\n",
        "        steps = proc_map.get(sm.id, [])\n",
        "        msgs = build_judge_messages(sm, steps)\n",
        "        try:\n",
        "            completion = client.chat.completions.parse(\n",
        "                model=JUDGE_MODEL,\n",
        "                messages=msgs,\n",
        "                temperature=JUDGE_TEMPERATURE,\n",
        "                response_format=JudgeOutput,\n",
        "            )\n",
        "            parsed: JudgeOutput = completion.choices[0].message.parsed  # type: ignore\n",
        "            rows.append({\n",
        "                'id': sm.id,\n",
        "                'general_score': parsed.general_score,\n",
        "                'specific_score': parsed.specific_score,\n",
        "                'total_score': parsed.final_score,\n",
        "                'notes': parsed.notes or '',\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"❌ 評価失敗: {sm.id}: {e}\")\n",
        "            if _is_insufficient_quota(e):\n",
        "                print(\"⚠️ APIクォータ不足のため、以降の採点を中断します。プラン/課金設定をご確認ください。\")\n",
        "                quota_exhausted = True\n",
        "            rows.append({\n",
        "                'id': sm.id,\n",
        "                'general_score': 0.0,\n",
        "                'specific_score': 0.0,\n",
        "                'total_score': 0.0,\n",
        "                'notes': 'evaluation_failed',\n",
        "            })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# 実行\n",
        "df = judge_with_llm(samples, generated_results)\n",
        "print(f\"✅ LLM-as-a-judge: Scored {len(df)} samples (0-10)\")\n",
        "try:\n",
        "    display(df[['id','general_score','specific_score','total_score']])\n",
        "except Exception:\n",
        "    print(df[['id','general_score','specific_score','total_score']])\n",
        "\n",
        "csv_path = out_dir / f'eval_llm_{ts}.csv'\n",
        "df.to_csv(csv_path, index=False, encoding=\"utf_8_sig\")\n",
        "print(f'📄 Saved: {csv_path}')\n",
        "\n",
        "try:\n",
        "    # ダウンロード確認ダイアログを出して、yならダウンロード\n",
        "    print(f\"Download file: {csv_path}\")\n",
        "    confirm = eval_js('confirm(\"生成されたCSVファイルをダウンロードしますか？\")')\n",
        "    if confirm:\n",
        "      colab_files.download(str(csv_path))\n",
        "    else:\n",
        "      print(\"ダウンロードをスキップしました。\")\n",
        "\n",
        "except Exception:\n",
        "    display(FileLink(str(csv_path.resolve())))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
