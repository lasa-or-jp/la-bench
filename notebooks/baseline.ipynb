{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrV21bF8yUQL",
        "outputId": "bd9e18c0-358b-49ad-9bf7-11c7c05d947b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âš ï¸ ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§å®Ÿè¡Œä¸­ã§ã™\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: ç’°å¢ƒè¨­å®šã¨ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
        "\"\"\"\n",
        "LA-Bench 2025: å®Ÿé¨“æ‰‹é †ç”Ÿæˆã‚¿ã‚¹ã‚¯\n",
        "Baseline Implementation for Google Colaboratory\n",
        "GitHub: https://github.com/lasa-or-jp/la-bench.git\n",
        "\"\"\"\n",
        "\n",
        "#@title 1. ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— { display-mode: \"form\" }\n",
        "#@markdown ã“ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã—ã¦å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã€ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ã—ã¾ã™ã€‚\n",
        "\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Colabã‹ã©ã†ã‹ã®ç¢ºèª\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"âœ… Google Colaboratoryç’°å¢ƒã‚’æ¤œå‡ºã—ã¾ã—ãŸ\")\n",
        "    # å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
        "    print(\"\\nğŸ“¦ å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...\")\n",
        "    !pip install -q openai pyyaml tqdm pandas\n",
        "\n",
        "    print(\"âœ… ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†\")\n",
        "\n",
        "    # GitHubãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³\n",
        "    REPO_URL = \"https://github.com/lasa-or-jp/la-bench.git\"\n",
        "    REPO_NAME = \"la-bench\"\n",
        "\n",
        "    if not os.path.exists(REPO_NAME):\n",
        "        print(f\"\\nğŸ“¥ ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ä¸­: {REPO_URL}\")\n",
        "        !git clone -q {REPO_URL}\n",
        "        print(f\"âœ… ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³å®Œäº†: {REPO_NAME}/\")\n",
        "    else:\n",
        "        print(f\"\\nğŸ“‚ ãƒªãƒã‚¸ãƒˆãƒªã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™: {REPO_NAME}/\")\n",
        "        print(\"ğŸ“¥ æœ€æ–°ç‰ˆã«æ›´æ–°ä¸­...\")\n",
        "        !cd {REPO_NAME} && git pull -q\n",
        "        print(\"âœ… æ›´æ–°å®Œäº†\")\n",
        "\n",
        "    # ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š\n",
        "    WORK_DIR = Path(REPO_NAME)\n",
        "    os.chdir(WORK_DIR)\n",
        "    print(f\"\\nğŸ“ ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {os.getcwd()}\")\n",
        "\n",
        "    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã®ç¢ºèª\n",
        "    print(\"\\nğŸ“Š ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ :\")\n",
        "    !ls -la\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"âš ï¸ ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§å®Ÿè¡Œä¸­ã§ã™\")\n",
        "    if Path.cwd().name == \"notebooks\":\n",
        "        os.chdir(Path.cwd().parent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PZr_6rXsyqlK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”‘ APIã‚­ãƒ¼: ********************LdwA\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: OpenAI APIã‚­ãƒ¼ã®è¨­å®š\n",
        "#@title 2. OpenAI API Keyè¨­å®š { display-mode: \"form\" }\n",
        "#@markdown OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ã‚­ãƒ¼ã¯å®‰å…¨ã«ç®¡ç†ã•ã‚Œã¾ã™ã€‚\n",
        "\n",
        "\n",
        "# APIã‚­ãƒ¼ã®å–å¾—æ–¹æ³•ã‚’é¸æŠ\n",
        "use_secrets = True  #@param {type:\"boolean\"}\n",
        "#@markdown â˜ï¸ Google Colab Secretsã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ãƒã‚§ãƒƒã‚¯\n",
        "\n",
        "if IN_COLAB:\n",
        "    import getpass\n",
        "    from google.colab import userdata\n",
        "    if use_secrets:\n",
        "        try:\n",
        "            # Colab Secretsã‹ã‚‰å–å¾—\n",
        "            API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "            print(\"âœ… APIã‚­ãƒ¼ã‚’Secretsã‹ã‚‰å–å¾—ã—ã¾ã—ãŸ\")\n",
        "        except Exception as e:\n",
        "            print(\"âš ï¸ Secretsã‹ã‚‰ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ\")\n",
        "            print(\"å·¦å´ã®ãƒ‘ãƒãƒ«ã®ğŸ”‘ã‚¢ã‚¤ã‚³ãƒ³ã‹ã‚‰'OPENAI_API_KEY'ã‚’è¨­å®šã—ã¦ãã ã•ã„\")\n",
        "            API_KEY = None\n",
        "    else:\n",
        "        # ç›´æ¥å…¥åŠ›\n",
        "        api_key_input = getpass.getpass(\"ğŸ”‘ OpenAI API Keyã‚’å…¥åŠ›: \")\n",
        "        if api_key_input:\n",
        "            API_KEY = api_key_input\n",
        "            os.environ['OPENAI_API_KEY'] = API_KEY\n",
        "            print(\"âœ… APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¾ã—ãŸ\")\n",
        "        else:\n",
        "            API_KEY = None\n",
        "            print(\"âš ï¸ APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯æ‰‹æ³•ã®ã¿ä½¿ç”¨ï¼‰\")\n",
        "else:\n",
        "    # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã®å ´åˆ\n",
        "    API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "    if not API_KEY:\n",
        "        API_KEY = input(\"OpenAI API Key: \")\n",
        "\n",
        "# APIã‚­ãƒ¼ã®æ¤œè¨¼\n",
        "if API_KEY:\n",
        "    print(f\"ğŸ”‘ APIã‚­ãƒ¼: {'*' * 20}{API_KEY[-4:]}\")\n",
        "else:\n",
        "    print(\"âš ï¸ GPTæ©Ÿèƒ½ã¯ä½¿ç”¨ã§ãã¾ã›ã‚“\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "71dPwmdnzEfP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "LA-Bench 2025 Baseline Implementation\n",
            "å®Ÿè¡Œç’°å¢ƒ: Local\n",
            "å®Ÿè¡Œæ™‚åˆ»: 2025-09-11 01:22:52\n",
            "OpenAIåˆ©ç”¨å¯èƒ½: True\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# Cell 3: ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¨è¨­å®š\n",
        "#@title 3. ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ { display-mode: \"form\" }\n",
        "\n",
        "import json\n",
        "import yaml\n",
        "import time\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Optional, Tuple, Set, Any\n",
        "from pathlib import Path\n",
        "from copy import deepcopy\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿å‡¦ç†\n",
        "import pandas as pd\n",
        "from dataclasses import dataclass, field\n",
        "\n",
        "# OpenAI API\n",
        "try:\n",
        "    from openai import OpenAI\n",
        "    OPENAI_AVAILABLE = True\n",
        "except ImportError:\n",
        "    OPENAI_AVAILABLE = False\n",
        "    print(\"âš ï¸ OpenAIãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“\")\n",
        "\n",
        "# ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ (Colabå¯¾å¿œ)\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# ãƒ­ã‚°è¨­å®š\n",
        "import logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    datefmt='%H:%M:%S'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"LA-Bench 2025 Baseline Implementation\")\n",
        "print(f\"å®Ÿè¡Œç’°å¢ƒ: {'Google Colab' if IN_COLAB else 'Local'}\")\n",
        "print(f\"å®Ÿè¡Œæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"OpenAIåˆ©ç”¨å¯èƒ½: {OPENAI_AVAILABLE and API_KEY is not None}\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0rypmgB20Yc2"
      },
      "outputs": [],
      "source": [
        "# Cell 4: ãƒ‡ãƒ¼ã‚¿æ§‹é€ \n",
        "#@title 4. ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®å®šç¾© { display-mode: \"form\" }\n",
        "\n",
        "@dataclass\n",
        "class Step:\n",
        "    id: int\n",
        "    text: str\n",
        "\n",
        "@dataclass\n",
        "class ExampleInput:\n",
        "    instruction: str\n",
        "    mandatory_objects: Set[str] = field(default_factory=set)\n",
        "    source_protocol_steps: List[Step] = field(default_factory=list)\n",
        "    expected_final_states: Set[str] = field(default_factory=set)\n",
        "    references: List[str] = field(default_factory=list)\n",
        "\n",
        "@dataclass\n",
        "class ExampleOutput:\n",
        "    procedure_steps: List[Step] = field(default_factory=list)\n",
        "\n",
        "@dataclass\n",
        "class Measurement:\n",
        "    specific_criteria: Dict[str, int] = field(default_factory=dict)\n",
        "\n",
        "@dataclass\n",
        "class ExampleSample:\n",
        "    id: str\n",
        "    input: ExampleInput\n",
        "    output: ExampleOutput\n",
        "    measurement: Optional[Measurement] = None\n",
        "\n",
        "def _to_set(x):\n",
        "    return set(x) if isinstance(x, (list, set, tuple)) else set()\n",
        "\n",
        "def _to_list(x):\n",
        "    return list(x) if isinstance(x, (list, set, tuple)) else (x if isinstance(x, list) else [])\n",
        "\n",
        "def _to_steps(x) -> List[Step]:\n",
        "    steps: List[Step] = []\n",
        "    arr = _to_list(x)\n",
        "    if not arr:\n",
        "        return steps\n",
        "    if isinstance(arr[0], dict):\n",
        "        for it in arr:\n",
        "            try:\n",
        "                sid = int(it.get(\"id\", len(steps) + 1))\n",
        "            except Exception:\n",
        "                sid = len(steps) + 1\n",
        "            steps.append(Step(id=sid, text=str(it.get(\"text\", \"\")).strip()))\n",
        "    else:\n",
        "        for idx, s in enumerate(arr, start=1):\n",
        "            steps.append(Step(id=idx, text=str(s).strip()))\n",
        "    return steps\n",
        "\n",
        "def parse_sample(obj: Dict[str, Any]) -> ExampleSample:\n",
        "    sid = obj.get(\"id\") or obj.get(\"sample_id\") or \"unknown\"\n",
        "    i = obj.get(\"input\", {})\n",
        "    o = obj.get(\"output\", {})\n",
        "    m = obj.get(\"measurement\", {})\n",
        "\n",
        "    # Measurement.specific_criteria ã‚’ dict ã«æ­£è¦åŒ–ï¼ˆlistå½¢å¼ã‚‚è¨±å®¹ï¼‰\n",
        "    sc_raw = m.get(\"specific_criteria\", {})\n",
        "    sc: Dict[str, int] = {}\n",
        "    if isinstance(sc_raw, dict):\n",
        "        for k, v in sc_raw.items():\n",
        "            try:\n",
        "                sc[str(k)] = int(v)\n",
        "            except Exception:\n",
        "                pass\n",
        "    elif isinstance(sc_raw, list):\n",
        "        for it in sc_raw:\n",
        "            try:\n",
        "                k = it.get(\"item\")\n",
        "                v = int(it.get(\"score\", 0))\n",
        "                if k:\n",
        "                    sc[str(k)] = v\n",
        "            except Exception:\n",
        "                pass\n",
        "\n",
        "    sample = ExampleSample(\n",
        "        id=str(sid),\n",
        "        input=ExampleInput(\n",
        "            instruction=str(i.get(\"instruction\", \"\")).strip(),\n",
        "            mandatory_objects=_to_set(i.get(\"mandatory_objects\", [])),\n",
        "            source_protocol_steps=_to_steps(i.get(\"source_protocol_steps\", [])),\n",
        "            expected_final_states=_to_set(i.get(\"expected_final_states\", [])),\n",
        "            references=_to_list(i.get(\"references\", [])),\n",
        "        ),\n",
        "        output=ExampleOutput(\n",
        "            procedure_steps=_to_steps(o.get(\"procedure_steps\", []))\n",
        "        ),\n",
        "        measurement=Measurement(specific_criteria=sc) if sc else None\n",
        "    )\n",
        "    return sample\n",
        "\n",
        "def load_example_jsonl(path: str):\n",
        "    samples = []\n",
        "    p = Path(path)\n",
        "    if not p.exists():\n",
        "        raise FileNotFoundError(f\"JSONL not found: {p}\")\n",
        "    for line in p.read_text(encoding=\"utf-8\").splitlines():\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "        try:\n",
        "            obj = json.loads(line)\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ JSONL parse error: {e}\")\n",
        "            continue\n",
        "        samples.append(parse_sample(obj))\n",
        "    return samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MXF0Ou0B6sFB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Loaded 5 samples from data/example/example.jsonl\n"
          ]
        }
      ],
      "source": [
        "# Cell 5: JSONLãƒ­ãƒ¼ãƒ€ãƒ¼ã®åˆ©ç”¨\n",
        "#@title 5. JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ { display-mode: \"form\" }\n",
        "\n",
        "jsonl_path = 'data/example/example.jsonl'  #@param {type:'string'}\n",
        "try:\n",
        "    samples = load_example_jsonl(jsonl_path)\n",
        "    print(f'âœ… Loaded {len(samples)} samples from {jsonl_path}')\n",
        "except Exception as e:\n",
        "    print(f'âŒ Load error: {e}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WZ94EpzOInJr"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "01:23:04 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "01:23:19 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "01:23:25 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "01:23:39 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "01:23:53 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… ç”Ÿæˆå®Œäº†: 5 samples\n",
            "ä¾‹: sample_1 â†’ 10 steps\n",
            "ğŸ“„ Saved JSONL: outputs/runs/generated_20250911_012353.jsonl\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<a href='/Users/kato/Dropbox/Programs/gensurv/la-bench/outputs/runs/generated_20250911_012353.jsonl' target='_blank'>/Users/kato/Dropbox/Programs/gensurv/la-bench/outputs/runs/generated_20250911_012353.jsonl</a><br>"
            ],
            "text/plain": [
              "/Users/kato/Dropbox/Programs/gensurv/la-bench/outputs/runs/generated_20250911_012353.jsonl"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Cell 6: å®Ÿé¨“æ‰‹é †ã®ç”Ÿæˆï¼ˆOpenAI, Pydanticæ§‹é€ åŒ–ï¼‰\n",
        "#@title 6. LLMã§ Input ã‹ã‚‰ Outputï¼ˆprocedure_stepsï¼‰ã‚’ç”Ÿæˆ { display-mode: \"form\" }\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«è¨­å®š\n",
        "MODEL_NAME = \"gpt-4.1-mini-2025-04-14\" #@param [\"gpt-4.1-mini-2025-04-14\", \"gpt-4o-2024-08-06\", \"gpt-5-2025-08-07\", \"gpt-5-mini-2025-08-07\", \"gpt-5-nano-2025-08-07\"]\n",
        "#@markdown gpt-4o-mini, gpt-4o-2024-08-06, ã‚ã‚‹ã„ã¯ãã‚Œä»¥é™ã®ãƒ¢ãƒ‡ãƒ«ã«å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚<br>\n",
        "#@markdown (Structured outputã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ãŸã‚) <br>\n",
        "#@markdown gpt-5ç³»ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€temperature=1.0ã¨ã—ã¦ãã ã•ã„ã€‚\n",
        "TEMPERATURE = 0.7 # @param\n",
        "\n",
        "#@markdown `build_messages`é–¢æ•°ã«ãŠã„ã¦ã€LLMã®å…¥åŠ›ã‚’è¨­è¨ˆã—ã¦ã„ã¾ã™ã€‚\n",
        "\n",
        "class StepModel(BaseModel):\n",
        "    id: int = Field(ge=1, description=\"ã‚¹ãƒ†ãƒƒãƒ—ç•ªå·\")\n",
        "    text: str = Field(description=\"å®Ÿé¨“æ‰‹é †ã®è©³ç´°ãªèª¬æ˜\")\n",
        "\n",
        "class GeneratedOutput(BaseModel):\n",
        "    procedure_steps: List[StepModel] = Field(\n",
        "        description=\"å®Ÿé¨“æ‰‹é †ã®ãƒªã‚¹ãƒˆ\",\n",
        "        min_items=1,\n",
        "        max_items=50\n",
        "    )\n",
        "\n",
        "def build_messages(sample: ExampleSample) -> list[dict]:\n",
        "    sys = (\n",
        "        \"ã‚ãªãŸã¯ç”Ÿå‘½ç§‘å­¦å®Ÿé¨“ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã® Input ã‚’èª­ã¿ã€\"\n",
        "        \"æ—¥æœ¬èªã§å®Ÿè¡Œå¯èƒ½ãªå®Ÿé¨“æ‰‹é †ï¼ˆprocedure_stepsï¼‰ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚\"\n",
        "        \"åˆ¶ç´„: ã‚¹ãƒ†ãƒƒãƒ—æ•°ã¯æœ€å¤§50ã€å„ã‚¹ãƒ†ãƒƒãƒ—ã¯10æ–‡ä»¥ä¸‹ã€idã¯1ã‹ã‚‰æ˜‡é †ã€‚\"\n",
        "    )\n",
        "    user_lines = []\n",
        "    user_lines.append(f\"ã€å®Ÿé¨“æŒ‡ç¤ºã€‘\\n{sample.input.instruction}\")\n",
        "    if sample.input.mandatory_objects:\n",
        "        user_lines.append(\"\\nã€ä½¿ç”¨ã™ã‚‹ç‰©å“ã€‘\")\n",
        "        for it in sorted(sample.input.mandatory_objects):\n",
        "            user_lines.append(f\"- {it}\")\n",
        "    if sample.input.source_protocol_steps:\n",
        "        user_lines.append(\"\\nã€å…ƒãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®æ‰‹é †ï¼ˆå‚è€ƒï¼‰ã€‘\")\n",
        "        for st in sample.input.source_protocol_steps:\n",
        "            user_lines.append(f\"- {st.id}. {st.text}\")\n",
        "    if sample.input.expected_final_states:\n",
        "        user_lines.append(\"\\nã€æœŸå¾…ã•ã‚Œã‚‹æœ€çµ‚çŠ¶æ…‹ã€‘\")\n",
        "        for fs in sorted(sample.input.expected_final_states):\n",
        "            user_lines.append(f\"- {fs}\")\n",
        "    if sample.input.references:\n",
        "        user_lines.append(\"\\nã€å‚è€ƒæ–‡çŒ®URLã€‘\")\n",
        "        for ref in sample.input.references:\n",
        "            user_lines.append(f\"- {ref}\")\n",
        "    usr = \"\\n\".join(user_lines)\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": sys},\n",
        "        {\"role\": \"user\", \"content\": usr},\n",
        "    ]\n",
        "\n",
        "def generate_outputs(samples: list[ExampleSample]) -> list[dict]:\n",
        "    client = OpenAI(api_key=API_KEY)\n",
        "    results: list[dict] = []\n",
        "    for sm in samples:\n",
        "        msgs = build_messages(sm)\n",
        "        try:\n",
        "            completion = client.chat.completions.parse(\n",
        "                model=MODEL_NAME,\n",
        "                messages=msgs,\n",
        "                temperature=TEMPERATURE,\n",
        "                response_format=GeneratedOutput,\n",
        "            )\n",
        "            parsed: GeneratedOutput = completion.choices[0].message.parsed  # type: ignore\n",
        "            steps = [\n",
        "                Step(id=s.id, text=s.text)\n",
        "                for s in sorted(parsed.procedure_steps, key=lambda x: x.id)\n",
        "            ][:50]\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ç”Ÿæˆå¤±æ•—: {sm.id}: {e}\")\n",
        "            steps = []  # no fallback\n",
        "        results.append({\n",
        "            \"id\": sm.id,\n",
        "            \"procedure_steps\": [{\"id\": s.id, \"text\": s.text} for s in steps],\n",
        "        })\n",
        "    print(f\"âœ… ç”Ÿæˆå®Œäº†: {len(results)} samples\")\n",
        "    return results\n",
        "\n",
        "# å®Ÿè¡Œ\n",
        "generated_results = generate_outputs(samples)\n",
        "if generated_results:\n",
        "    print(f\"ä¾‹: {generated_results[0]['id']} â†’ {len(generated_results[0]['procedure_steps'])} steps\")\n",
        "\n",
        "# ç”Ÿæˆçµæœã‚’ JSONL ã§ä¿å­˜ã—ã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ã‚’è¡¨ç¤º\n",
        "ts = time.strftime('%Y%m%d_%H%M%S')\n",
        "out_dir = Path('./outputs/runs')\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "jsonl_path = out_dir / f'generated_{ts}.jsonl'\n",
        "with jsonl_path.open('w', encoding='utf-8') as f:\n",
        "    for rec in generated_results:\n",
        "        obj = {\"id\": rec[\"id\"], \"output\": {\"procedure_steps\": rec[\"procedure_steps\"]}}\n",
        "        line = json.dumps(obj, ensure_ascii=False, separators=(\",\", \":\"))\n",
        "        f.write(line + \"\\n\")\n",
        "print(f\"ğŸ“„ Saved JSONL: {jsonl_path}\")\n",
        "\n",
        "# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆColab/ãƒ­ãƒ¼ã‚«ãƒ«åŒæ–¹ã«å¯¾å¿œï¼‰\n",
        "try:\n",
        "    from google.colab import files as colab_files  # type: ignore\n",
        "    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç¢ºèªãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã‚’å‡ºã—ã¦ã€yãªã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
        "    from google.colab.output import eval_js\n",
        "    print(f\"Download file: {jsonl_path}\")\n",
        "    confirm = eval_js('confirm(\"ç”Ÿæˆã•ã‚ŒãŸJSONLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã‹ï¼Ÿ\")')\n",
        "    if confirm:\n",
        "      colab_files.download(str(jsonl_path))\n",
        "    else:\n",
        "      print(\"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚\")\n",
        "\n",
        "except Exception:\n",
        "    from IPython.display import FileLink, display\n",
        "    display(FileLink(str(jsonl_path.resolve())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wYtMf3bJOzcN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "01:24:04 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "01:24:09 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "01:24:17 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "01:24:21 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "01:24:30 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… LLM-as-a-judge: Scored 5 samples (0-10)\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "id",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "general_score",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "specific_score",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "total_score",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "ref": "2a363cc5-831e-4fed-8f6d-c5ca8278cec7",
              "rows": [
                [
                  "0",
                  "sample_1",
                  "5.0",
                  "4.0",
                  "9.0"
                ],
                [
                  "1",
                  "sample_2",
                  "5.0",
                  "3.0",
                  "8.0"
                ],
                [
                  "2",
                  "sample_3",
                  "5.0",
                  "3.0",
                  "8.0"
                ],
                [
                  "3",
                  "sample_4",
                  "5.0",
                  "3.0",
                  "8.0"
                ],
                [
                  "4",
                  "sample_5",
                  "5.0",
                  "3.0",
                  "8.0"
                ]
              ],
              "shape": {
                "columns": 4,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>general_score</th>\n",
              "      <th>specific_score</th>\n",
              "      <th>total_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sample_1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sample_2</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sample_3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sample_4</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sample_5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  general_score  specific_score  total_score\n",
              "0  sample_1            5.0             4.0          9.0\n",
              "1  sample_2            5.0             3.0          8.0\n",
              "2  sample_3            5.0             3.0          8.0\n",
              "3  sample_4            5.0             3.0          8.0\n",
              "4  sample_5            5.0             3.0          8.0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“„ Saved: outputs/runs/eval_llm_20250911_012353.csv\n",
            "Download file: outputs/runs/eval_llm_20250911_012353.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<a href='/Users/kato/Dropbox/Programs/gensurv/la-bench/outputs/runs/eval_llm_20250911_012353.csv' target='_blank'>/Users/kato/Dropbox/Programs/gensurv/la-bench/outputs/runs/eval_llm_20250911_012353.csv</a><br>"
            ],
            "text/plain": [
              "/Users/kato/Dropbox/Programs/gensurv/la-bench/outputs/runs/eval_llm_20250911_012353.csv"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Cell 7: LLM-as-a-judge è©•ä¾¡ï¼ˆ10ç‚¹æº€ç‚¹ï¼‰\n",
        "#@title 7. LLM ã§å…±é€š5ç‚¹ + å€‹åˆ¥5ç‚¹ã‚’æ¡ç‚¹ { display-mode: \"form\" }\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "from typing import List, Optional\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "try:\n",
        "    from openai import OpenAI\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\"OpenAI SDK v1 ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚`uv add openai` ã§è¿½åŠ ã—ã¦ãã ã•ã„ã€‚\") from e\n",
        "\n",
        "JUDGE_MODEL = \"gpt-4.1-mini\"  # é«˜æ€§èƒ½æ¨å¥¨ãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›´å¯\n",
        "JUDGE_TEMPERATURE = 0.2\n",
        "\n",
        "class JudgeOutput(BaseModel):\n",
        "    general_score: float = Field(ge=0, le=5)\n",
        "    specific_score: float = Field(ge=0, le=5)\n",
        "    final_score: float = Field(ge=0, le=10)\n",
        "    general_reason: str\n",
        "    specific_matches: List[str] = []\n",
        "    notes: Optional[str] = None\n",
        "\n",
        "def build_judge_messages(sample: ExampleSample, steps: List[Step]) -> list[dict]:\n",
        "    # è©•ä¾¡åŸºæº–ï¼ˆå…±é€š5ç‚¹ + å€‹åˆ¥5ç‚¹ï¼‰\n",
        "    system = (\n",
        "        \"ã‚ãªãŸã¯ç”Ÿå‘½ç§‘å­¦å®Ÿé¨“ã®å°‚é–€å®¶ã§ã‚ã‚Šã€å…¬å¹³ãªæ¡ç‚¹è€…ã§ã™ã€‚\"\n",
        "        \"ä»¥ä¸‹ã®åŸºæº–ã«å¾“ã£ã¦ã€ä¸ãˆã‚‰ã‚ŒãŸ Input ã¨ç”Ÿæˆæ‰‹é †ï¼ˆOutputï¼‰ã‚’è©•ä¾¡ã—ã€\"\n",
        "        \"general_score(0-5) ã¨ specific_score(0-5) ã¨ final_score(0-10) ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\"\n",
        "        \"\\n\\n[å…±é€šæ¡ç‚¹åŸºæº– 5ç‚¹æº€ç‚¹]\\n\"\n",
        "        \"åŠ ç‚¹(+1ãšã¤): 1) å®Ÿé¨“æŒ‡ç¤ºã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åæ˜ , 2) ä½¿ç”¨ã™ã‚‹ç‰©å“ã®åæ˜ , 3) å…ƒæ‰‹é †ã®è«–ç†åæ˜ , 4) æœŸå¾…ã•ã‚Œã‚‹æœ€çµ‚çŠ¶æ…‹ã®é”æˆ, 5) é©åˆ‡ãªè£œå®Œã€‚\\n\"\n",
        "        \"æ¸›ç‚¹: ä¸è‡ªç„¶ãªæ—¥æœ¬èª/ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³, è¨ˆç®—ãƒŸã‚¹, æ‰‹é †çŸ›ç›¾ã€‚\\n\"\n",
        "        \"ä¸Šé™: å…¥åŠ›æ‰‹é †ã®ä¸¸å†™ã—ç­‰ã®éåº¦ã®å®‰å…¨æ€§ãŒè¦‹ã‚‰ã‚Œã‚‹å ´åˆã€general_score ã¯æœ€å¤§2ç‚¹ã«åˆ¶é™ã€‚\\n\\n\"\n",
        "        \"[å€‹åˆ¥æ¡ç‚¹åŸºæº– 5ç‚¹æº€ç‚¹]\\n\"\n",
        "        \"ä¸ãˆã‚‰ã‚ŒãŸ specific_criteria ã®å„ item ãŒæ‰‹é †ã«å«ã¾ã‚Œã‚‹/æº€ãŸã™ãªã‚‰ã€ãã® score ã‚’åŠ ç‚¹ï¼ˆåˆè¨ˆ5ç‚¹ã§ä¸Šé™ï¼‰ã€‚\"\n",
        "    )\n",
        "\n",
        "    parts = []\n",
        "    parts.append(f\"ã€å®Ÿé¨“æŒ‡ç¤ºã€‘\\n{sample.input.instruction}\")\n",
        "    if sample.input.mandatory_objects:\n",
        "        parts.append(\"\\nã€ä½¿ç”¨ã™ã‚‹ç‰©å“ã€‘\")\n",
        "        for it in sorted(sample.input.mandatory_objects):\n",
        "            parts.append(f\"- {it}\")\n",
        "    if sample.input.source_protocol_steps:\n",
        "        parts.append(\"\\nã€å…ƒãƒ—ãƒ­ãƒˆã‚³ãƒ«ã®æ‰‹é †ï¼ˆå‚è€ƒï¼‰ã€‘\")\n",
        "        for st in sample.input.source_protocol_steps:\n",
        "            parts.append(f\"- {st.id}. {st.text}\")\n",
        "    if sample.input.expected_final_states:\n",
        "        parts.append(\"\\nã€æœŸå¾…ã•ã‚Œã‚‹æœ€çµ‚çŠ¶æ…‹ã€‘\")\n",
        "        for fs in sorted(sample.input.expected_final_states):\n",
        "            parts.append(f\"- {fs}\")\n",
        "    if sample.input.references:\n",
        "        parts.append(\"\\nã€å‚è€ƒæ–‡çŒ®ã€‘\")\n",
        "        for ref in sample.input.references:\n",
        "            parts.append(f\"- {ref}\")\n",
        "\n",
        "    parts.append(\"\\nã€ç”Ÿæˆæ‰‹é †ï¼ˆOutputï¼‰ã€‘\")\n",
        "    for s in steps:\n",
        "        parts.append(f\"- {s.id}. {s.text}\")\n",
        "\n",
        "    parts.append(\"\\nã€specific_criteriaã€‘\")\n",
        "    if sample.measurement and sample.measurement.specific_criteria:\n",
        "        for item, sc in sample.measurement.specific_criteria.items():\n",
        "            parts.append(f\"- ({int(sc)}ç‚¹) {item}\")\n",
        "    else:\n",
        "        parts.append(\"- ãªã—\")\n",
        "\n",
        "    user = \"\\n\".join(parts)\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": user},\n",
        "    ]\n",
        "\n",
        "def judge_with_llm(samples: List[ExampleSample], generated: list[dict]) -> pd.DataFrame:\n",
        "    client = OpenAI(api_key=API_KEY) if 'API_KEY' in globals() and API_KEY else OpenAI()\n",
        "    proc_map = {g['id']: [Step(id=it['id'], text=it['text']) for it in g['procedure_steps']] for g in generated}\n",
        "    rows = []\n",
        "    quota_exhausted = False\n",
        "    def _is_insufficient_quota(err: Exception) -> bool:\n",
        "        s = str(err)\n",
        "        return 'insufficient_quota' in s or 'You exceeded your current quota' in s\n",
        "    for sm in samples:\n",
        "        if quota_exhausted:\n",
        "            print(f\"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—æ¡ç‚¹: {sm.id}ï¼ˆã‚¯ã‚©ãƒ¼ã‚¿ä¸è¶³ï¼‰\")\n",
        "            rows.append({\n",
        "                'id': sm.id,\n",
        "                'general_score': 0.0,\n",
        "                'specific_score': 0.0,\n",
        "                'total_score': 0.0,\n",
        "                'notes': 'skipped_due_to_quota',\n",
        "            })\n",
        "            continue\n",
        "        steps = proc_map.get(sm.id, [])\n",
        "        msgs = build_judge_messages(sm, steps)\n",
        "        try:\n",
        "            completion = client.chat.completions.parse(\n",
        "                model=JUDGE_MODEL,\n",
        "                messages=msgs,\n",
        "                temperature=JUDGE_TEMPERATURE,\n",
        "                response_format=JudgeOutput,\n",
        "            )\n",
        "            parsed: JudgeOutput = completion.choices[0].message.parsed  # type: ignore\n",
        "            rows.append({\n",
        "                'id': sm.id,\n",
        "                'general_score': parsed.general_score,\n",
        "                'specific_score': parsed.specific_score,\n",
        "                'total_score': parsed.final_score,\n",
        "                'notes': parsed.notes or '',\n",
        "            })\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ è©•ä¾¡å¤±æ•—: {sm.id}: {e}\")\n",
        "            if _is_insufficient_quota(e):\n",
        "                print(\"âš ï¸ APIã‚¯ã‚©ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚ã€ä»¥é™ã®æ¡ç‚¹ã‚’ä¸­æ–­ã—ã¾ã™ã€‚ãƒ—ãƒ©ãƒ³/èª²é‡‘è¨­å®šã‚’ã”ç¢ºèªãã ã•ã„ã€‚\")\n",
        "                quota_exhausted = True\n",
        "            rows.append({\n",
        "                'id': sm.id,\n",
        "                'general_score': 0.0,\n",
        "                'specific_score': 0.0,\n",
        "                'total_score': 0.0,\n",
        "                'notes': 'evaluation_failed',\n",
        "            })\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# å®Ÿè¡Œ\n",
        "df = judge_with_llm(samples, generated_results)\n",
        "print(f\"âœ… LLM-as-a-judge: Scored {len(df)} samples (0-10)\")\n",
        "try:\n",
        "    display(df[['id','general_score','specific_score','total_score']])\n",
        "except Exception:\n",
        "    print(df[['id','general_score','specific_score','total_score']])\n",
        "\n",
        "csv_path = out_dir / f'eval_llm_{ts}.csv'\n",
        "df.to_csv(csv_path, index=False, encoding=\"utf_8_sig\")\n",
        "print(f'ğŸ“„ Saved: {csv_path}')\n",
        "\n",
        "try:\n",
        "    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç¢ºèªãƒ€ã‚¤ã‚¢ãƒ­ã‚°ã‚’å‡ºã—ã¦ã€yãªã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
        "    print(f\"Download file: {csv_path}\")\n",
        "    confirm = eval_js('confirm(\"ç”Ÿæˆã•ã‚ŒãŸCSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã‹ï¼Ÿ\")')\n",
        "    if confirm:\n",
        "      colab_files.download(str(csv_path))\n",
        "    else:\n",
        "      print(\"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚\")\n",
        "\n",
        "except Exception:\n",
        "    display(FileLink(str(csv_path.resolve())))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
