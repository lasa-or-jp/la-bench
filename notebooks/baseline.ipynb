{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b40ac992b90b4aaa88a76bfdfbdac9c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97a08cebeac54ab09f411be9aba92df7",
              "IPY_MODEL_44cf68d6ead14da0aa7728d2dcd62dea",
              "IPY_MODEL_04780b69229e4843b6afe0749eea65f0"
            ],
            "layout": "IPY_MODEL_2f63e788f9cb4cee8c5f7a1bf3493dc2"
          }
        },
        "97a08cebeac54ab09f411be9aba92df7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c82338319c7243c2b140cab742e6cbf6",
            "placeholder": "​",
            "style": "IPY_MODEL_f35d254373ad43c9b9286d6f09c60cce",
            "value": "Processing example dataset: 100%"
          }
        },
        "44cf68d6ead14da0aa7728d2dcd62dea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59189fe39e3d4138ac6b2827be7c62e6",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb000000b4984fba9929e157d7325495",
            "value": 2
          }
        },
        "04780b69229e4843b6afe0749eea65f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56626730a9a546908e25dee10e500ba3",
            "placeholder": "​",
            "style": "IPY_MODEL_ef88243320c44924ac5e804ffee3069b",
            "value": " 2/2 [01:50&lt;00:00, 53.95s/it]"
          }
        },
        "2f63e788f9cb4cee8c5f7a1bf3493dc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c82338319c7243c2b140cab742e6cbf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f35d254373ad43c9b9286d6f09c60cce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59189fe39e3d4138ac6b2827be7c62e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb000000b4984fba9929e157d7325495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56626730a9a546908e25dee10e500ba3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef88243320c44924ac5e804ffee3069b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrV21bF8yUQL",
        "outputId": "42e683c8-bb8c-43f3-ef4a-5f7fd9f10e2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Google Colaboratory環境を検出しました\n",
            "\n",
            "📦 必要なライブラリをインストール中...\n",
            "✅ ライブラリのインストール完了\n",
            "\n",
            "📥 リポジトリをクローン中: https://github.com/lasa-or-jp/la-bench.git\n",
            "✅ リポジトリのクローン完了: la-bench/\n",
            "\n",
            "📍 作業ディレクトリ: /content/la-bench/la-bench/la-bench\n",
            "\n",
            "📊 プロジェクト構造:\n",
            "total 52\n",
            "drwxr-xr-x  8 root root 4096 Aug 10 09:36 .\n",
            "drwxr-xr-x 10 root root 4096 Aug 10 09:36 ..\n",
            "drwxr-xr-x  4 root root 4096 Aug 10 09:36 code\n",
            "-rw-r--r--  1 root root 2658 Aug 10 09:36 CONTRIBUTING.md\n",
            "drwxr-xr-x  4 root root 4096 Aug 10 09:36 data\n",
            "drwxr-xr-x  2 root root 4096 Aug 10 09:36 docs\n",
            "drwxr-xr-x  8 root root 4096 Aug 10 09:36 .git\n",
            "drwxr-xr-x  3 root root 4096 Aug 10 09:36 .github\n",
            "-rw-r--r--  1 root root  971 Aug 10 09:36 .gitignore\n",
            "-rw-r--r--  1 root root 1101 Aug 10 09:36 LICENSE\n",
            "-rw-r--r--  1 root root 4196 Aug 10 09:36 README.md\n",
            "drwxr-xr-x  2 root root 4096 Aug 10 09:36 submissions\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: 環境設定とセットアップ\n",
        "\"\"\"\n",
        "LA-Bench 2025: 実験手順生成タスク\n",
        "Baseline Implementation for Google Colaboratory\n",
        "GitHub: https://github.com/lasa-or-jp/la-bench.git\n",
        "\"\"\"\n",
        "\n",
        "#@title 1. 環境セットアップ { display-mode: \"form\" }\n",
        "#@markdown このセルを実行して必要なライブラリをインストールし、リポジトリをクローンします。\n",
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Colabかどうかの確認\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"✅ Google Colaboratory環境を検出しました\")\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"⚠️ ローカル環境で実行中です\")\n",
        "\n",
        "# 必要なライブラリのインストール\n",
        "print(\"\\n📦 必要なライブラリをインストール中...\")\n",
        "!pip install -q openai tenacity pyyaml tqdm python-Levenshtein pandas numpy matplotlib seaborn\n",
        "\n",
        "print(\"✅ ライブラリのインストール完了\")\n",
        "\n",
        "# GitHubリポジトリのクローン\n",
        "REPO_URL = \"https://github.com/lasa-or-jp/la-bench.git\"\n",
        "REPO_NAME = \"la-bench\"\n",
        "\n",
        "if not os.path.exists(REPO_NAME):\n",
        "    print(f\"\\n📥 リポジトリをクローン中: {REPO_URL}\")\n",
        "    !git clone -q {REPO_URL}\n",
        "    print(f\"✅ リポジトリのクローン完了: {REPO_NAME}/\")\n",
        "else:\n",
        "    print(f\"\\n📂 リポジトリは既に存在します: {REPO_NAME}/\")\n",
        "    print(\"📥 最新版に更新中...\")\n",
        "    !cd {REPO_NAME} && git pull -q\n",
        "    print(\"✅ 更新完了\")\n",
        "\n",
        "# 作業ディレクトリの設定\n",
        "WORK_DIR = Path(REPO_NAME)\n",
        "os.chdir(WORK_DIR)\n",
        "print(f\"\\n📍 作業ディレクトリ: {os.getcwd()}\")\n",
        "\n",
        "# ディレクトリ構造の確認\n",
        "print(\"\\n📊 プロジェクト構造:\")\n",
        "!ls -la"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: OpenAI APIキーの設定\n",
        "#@title 2. OpenAI API Key設定 { display-mode: \"form\" }\n",
        "#@markdown OpenAI APIキーを入力してください。キーは安全に管理されます。\n",
        "\n",
        "import getpass\n",
        "from google.colab import userdata\n",
        "\n",
        "# APIキーの取得方法を選択\n",
        "use_secrets = True  #@param {type:\"boolean\"}\n",
        "#@markdown ☝️ Google Colab Secretsを使用する場合はチェック\n",
        "\n",
        "if IN_COLAB:\n",
        "    if use_secrets:\n",
        "        try:\n",
        "            # Colab Secretsから取得\n",
        "            API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "            print(\"✅ APIキーをSecretsから取得しました\")\n",
        "        except Exception as e:\n",
        "            print(\"⚠️ Secretsからの取得に失敗しました\")\n",
        "            print(\"左側のパネルの🔑アイコンから'OPENAI_API_KEY'を設定してください\")\n",
        "            API_KEY = None\n",
        "    else:\n",
        "        # 直接入力\n",
        "        api_key_input = getpass.getpass(\"🔑 OpenAI API Keyを入力: \")\n",
        "        if api_key_input:\n",
        "            API_KEY = api_key_input\n",
        "            os.environ['OPENAI_API_KEY'] = API_KEY\n",
        "            print(\"✅ APIキーが設定されました\")\n",
        "        else:\n",
        "            API_KEY = None\n",
        "            print(\"⚠️ APIキーが設定されていません（ヒューリスティック手法のみ使用）\")\n",
        "else:\n",
        "    # ローカル環境の場合\n",
        "    API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "    if not API_KEY:\n",
        "        API_KEY = input(\"OpenAI API Key: \")\n",
        "\n",
        "# APIキーの検証\n",
        "if API_KEY:\n",
        "    print(f\"🔑 APIキー: {'*' * 20}{API_KEY[-4:]}\")\n",
        "else:\n",
        "    print(\"⚠️ GPT機能は使用できません\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZr_6rXsyqlK",
        "outputId": "6ff0f0c2-3bb0-49b0-88cd-c7c4592ba502"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ APIキーをSecretsから取得しました\n",
            "🔑 APIキー: ********************JacA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: ライブラリのインポートと設定\n",
        "#@title 3. ライブラリのインポート { display-mode: \"form\" }\n",
        "\n",
        "import json\n",
        "import yaml\n",
        "import re\n",
        "import time\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Optional, Tuple, Any\n",
        "from copy import deepcopy\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# データ処理\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from dataclasses import dataclass, field, asdict\n",
        "\n",
        "# OpenAI API\n",
        "try:\n",
        "    from openai import OpenAI\n",
        "    OPENAI_AVAILABLE = True\n",
        "except ImportError:\n",
        "    OPENAI_AVAILABLE = False\n",
        "    print(\"⚠️ OpenAIライブラリが利用できません\")\n",
        "\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential\n",
        "\n",
        "# 評価メトリクス\n",
        "from difflib import SequenceMatcher\n",
        "try:\n",
        "    import Levenshtein\n",
        "    LEVENSHTEIN_AVAILABLE = True\n",
        "except ImportError:\n",
        "    LEVENSHTEIN_AVAILABLE = False\n",
        "\n",
        "# プログレスバー (Colab対応)\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# 可視化\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "if IN_COLAB:\n",
        "    # Colabでの日本語フォント設定\n",
        "    !apt-get -q install fonts-noto-cjk > /dev/null 2>&1\n",
        "    import matplotlib\n",
        "    import matplotlib.font_manager as fm\n",
        "\n",
        "    # フォントキャッシュをクリアして再構築\n",
        "    # fontManagerのフォントリストをクリア\n",
        "    fm.fontManager.ttflist.clear()\n",
        "    fm.fontManager.afmlist.clear()\n",
        "\n",
        "    # fontManagerを再初期化（新しいフォントを検出）\n",
        "    fm.fontManager = fm.FontManager()\n",
        "\n",
        "    # 利用可能なフォントを確認\n",
        "    available_fonts = [f.name for f in fm.fontManager.ttflist]\n",
        "    japanese_fonts = [f for f in available_fonts if 'CJK' in f or 'Noto' in f]\n",
        "\n",
        "    if japanese_fonts:\n",
        "        print(f\"✅ 日本語フォントを検出: {japanese_fonts[:3]}...\")  # 最初の3つだけ表示\n",
        "\n",
        "        # 日本語フォントの設定\n",
        "        plt.rcParams['font.family'] = 'sans-serif'\n",
        "        plt.rcParams['font.sans-serif'] = ['Noto Sans CJK JP'] + plt.rcParams['font.sans-serif']\n",
        "\n",
        "        # マイナス記号の表示設定\n",
        "        plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "        print(\"✅ 日本語フォントを設定しました\")\n",
        "    else:\n",
        "        print(\"⚠️ 日本語フォントが見つかりません。グラフの日本語が文字化けする可能性があります\")\n",
        "\n",
        "# ログ設定\n",
        "import logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    datefmt='%H:%M:%S'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"LA-Bench 2025 Baseline Implementation\")\n",
        "print(f\"実行環境: {'Google Colab' if IN_COLAB else 'Local'}\")\n",
        "print(f\"実行時刻: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"OpenAI利用可能: {OPENAI_AVAILABLE and API_KEY is not None}\")\n",
        "print(\"=\"*60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71dPwmdnzEfP",
        "outputId": "ab7cc1b1-bc83-4b47-b0b4-a234d6203631"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 日本語フォントを検出: ['Noto Sans CJK JP', 'Noto Serif CJK JP', 'Noto Sans CJK JP']...\n",
            "✅ 日本語フォントを設定しました\n",
            "============================================================\n",
            "LA-Bench 2025 Baseline Implementation\n",
            "実行環境: Google Colab\n",
            "実行時刻: 2025-08-10 09:36:41\n",
            "OpenAI利用可能: True\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: データ構造とユーティリティ\n",
        "#@title 4. データ構造の定義 { display-mode: \"form\" }\n",
        "\n",
        "@dataclass\n",
        "class ProtocolStep:\n",
        "    \"\"\"プロトコルのステップ\"\"\"\n",
        "    id: int\n",
        "    text: str\n",
        "\n",
        "@dataclass\n",
        "class ResourceInfo:\n",
        "    \"\"\"リソース情報（エイリアス、マッピング、制約）\"\"\"\n",
        "    aliases: Dict[str, str] = field(default_factory=dict)\n",
        "    mappings: Dict[str, str] = field(default_factory=dict)\n",
        "    constraints: Dict[str, Any] = field(default_factory=dict)\n",
        "\n",
        "@dataclass\n",
        "class ExperimentTask:\n",
        "    \"\"\"実験タスクのデータ構造\"\"\"\n",
        "    id: str\n",
        "    instruction: str\n",
        "    protocol: List[ProtocolStep]\n",
        "    resources: ResourceInfo\n",
        "    ground_truth: Optional[List[ProtocolStep]] = None\n",
        "\n",
        "    @classmethod\n",
        "    def from_json(cls, json_data: Dict) -> 'ExperimentTask':\n",
        "        \"\"\"JSONデータからExperimentTaskを生成\"\"\"\n",
        "        protocol_steps = [\n",
        "            ProtocolStep(id=step['id'], text=step['text'])\n",
        "            for step in json_data['protocol']['steps']\n",
        "        ]\n",
        "\n",
        "        resources = ResourceInfo(\n",
        "            aliases=json_data['resources'].get('aliases', {}),\n",
        "            mappings=json_data['resources'].get('mappings', {}),\n",
        "            constraints=json_data['resources'].get('constraints', {})\n",
        "        )\n",
        "\n",
        "        ground_truth = None\n",
        "        if 'ground_truth' in json_data and json_data['ground_truth']:\n",
        "            ground_truth = [\n",
        "                ProtocolStep(id=step['id'], text=step['text'])\n",
        "                for step in json_data['ground_truth']['steps']\n",
        "            ]\n",
        "\n",
        "        return cls(\n",
        "            id=json_data['id'],\n",
        "            instruction=json_data['instruction'],\n",
        "            protocol=protocol_steps,\n",
        "            resources=resources,\n",
        "            ground_truth=ground_truth\n",
        "        )\n",
        "\n",
        "    @classmethod\n",
        "    def from_yaml(cls, yaml_data: Dict) -> 'ExperimentTask':\n",
        "        \"\"\"YAMLデータからExperimentTaskを生成\"\"\"\n",
        "        return cls.from_json(yaml_data)\n",
        "\n",
        "print(\"✅ データ構造を定義しました\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rypmgB20Yc2",
        "outputId": "00b33c32-189d-4d35-af47-730ffa4cb127"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ データ構造を定義しました\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: データローダー（Colab対応）\n",
        "#@title 5. データローダーの実装 { display-mode: \"form\" }\n",
        "\n",
        "class DataLoader:\n",
        "    \"\"\"実験タスクデータのローダー\"\"\"\n",
        "\n",
        "    def __init__(self, data_dir: str = \"./data\"):\n",
        "        self.data_dir = Path(data_dir)\n",
        "        if not self.data_dir.exists():\n",
        "            logger.warning(f\"データディレクトリが存在しません: {self.data_dir}\")\n",
        "            self.data_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    def check_data_availability(self) -> Dict[str, bool]:\n",
        "        \"\"\"データの利用可能性をチェック\"\"\"\n",
        "        availability = {\n",
        "            'example_json': False,\n",
        "            'example_yaml': False,\n",
        "            'public': False,\n",
        "            'private': False\n",
        "        }\n",
        "\n",
        "        if (self.data_dir / \"example\" / \"json\").exists():\n",
        "            json_files = list((self.data_dir / \"example\" / \"json\").glob(\"task_*.json\"))\n",
        "            availability['example_json'] = len(json_files) > 0\n",
        "\n",
        "        if (self.data_dir / \"example\" / \"yaml\").exists():\n",
        "            yaml_files = list((self.data_dir / \"example\" / \"yaml\").glob(\"task_*.yaml\"))\n",
        "            availability['example_yaml'] = len(yaml_files) > 0\n",
        "\n",
        "        if (self.data_dir / \"public\").exists():\n",
        "            public_files = list((self.data_dir / \"public\").glob(\"pub_task_*.yaml\"))\n",
        "            availability['public'] = len(public_files) > 0\n",
        "\n",
        "        if (self.data_dir / \"private\").exists():\n",
        "            private_files = list((self.data_dir / \"private\").glob(\"pri_task_*.yaml\"))\n",
        "            availability['private'] = len(private_files) > 0\n",
        "\n",
        "        return availability\n",
        "\n",
        "    def load_task(self, file_path: str) -> ExperimentTask:\n",
        "        \"\"\"単一タスクファイルの読み込み\"\"\"\n",
        "        file_path = Path(file_path)\n",
        "\n",
        "        if not file_path.exists():\n",
        "            raise FileNotFoundError(f\"タスクファイルが見つかりません: {file_path}\")\n",
        "\n",
        "        if file_path.suffix == '.json':\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                data = json.load(f)\n",
        "            return ExperimentTask.from_json(data)\n",
        "        elif file_path.suffix == '.yaml':\n",
        "            with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                data = yaml.safe_load(f)\n",
        "            return ExperimentTask.from_yaml(data)\n",
        "        else:\n",
        "            raise ValueError(f\"サポートされていないファイル形式: {file_path.suffix}\")\n",
        "\n",
        "    def load_dataset(self, dataset_type: str = \"example\") -> List[ExperimentTask]:\n",
        "        \"\"\"データセット全体の読み込み\"\"\"\n",
        "        tasks = []\n",
        "\n",
        "        if dataset_type == \"example\":\n",
        "            # JSONとYAMLの両方をチェック\n",
        "            json_dir = self.data_dir / \"example\" / \"json\"\n",
        "            yaml_dir = self.data_dir / \"example\" / \"yaml\"\n",
        "\n",
        "            # JSON優先で読み込み\n",
        "            if json_dir.exists():\n",
        "                for file_path in sorted(json_dir.glob(\"task_*.json\")):\n",
        "                    try:\n",
        "                        tasks.append(self.load_task(file_path))\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"タスク読み込みエラー {file_path}: {e}\")\n",
        "            elif yaml_dir.exists():\n",
        "                for file_path in sorted(yaml_dir.glob(\"task_*.yaml\")):\n",
        "                    try:\n",
        "                        tasks.append(self.load_task(file_path))\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"タスク読み込みエラー {file_path}: {e}\")\n",
        "\n",
        "        elif dataset_type == \"public\":\n",
        "            public_dir = self.data_dir / \"public\"\n",
        "            if public_dir.exists():\n",
        "                for file_path in sorted(public_dir.glob(\"pub_task_*.yaml\")):\n",
        "                    try:\n",
        "                        tasks.append(self.load_task(file_path))\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"タスク読み込みエラー {file_path}: {e}\")\n",
        "\n",
        "        elif dataset_type == \"private\":\n",
        "            private_dir = self.data_dir / \"private\"\n",
        "            if private_dir.exists():\n",
        "                for file_path in sorted(private_dir.glob(\"pri_task_*.yaml\")):\n",
        "                    try:\n",
        "                        tasks.append(self.load_task(file_path))\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"タスク読み込みエラー {file_path}: {e}\")\n",
        "\n",
        "        logger.info(f\"{dataset_type}データセットから{len(tasks)}個のタスクを読み込みました\")\n",
        "        return tasks\n",
        "\n",
        "# データ利用可能性のチェック\n",
        "loader = DataLoader()\n",
        "availability = loader.check_data_availability()\n",
        "print(\"📊 データ利用可能性:\")\n",
        "for key, available in availability.items():\n",
        "    status = \"✅\" if available else \"❌\"\n",
        "    print(f\"  {status} {key}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXF0Ou0B6sFB",
        "outputId": "2df67600-8350-4183-f5d2-62705c677b90"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 データ利用可能性:\n",
            "  ❌ example_json\n",
            "  ❌ example_yaml\n",
            "  ❌ public\n",
            "  ❌ private\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: サンプルデータの作成（データがない場合）\n",
        "#@title 6. サンプルデータの作成 { display-mode: \"form\" }\n",
        "#@markdown データが存在しない場合、サンプルデータを作成します\n",
        "\n",
        "create_sample = True #@param {type:\"boolean\"}\n",
        "\n",
        "if create_sample and not any(availability.values()):\n",
        "    print(\"📝 サンプルデータを作成中...\")\n",
        "\n",
        "    # ディレクトリの作成\n",
        "    sample_dir = Path(\"data/example/json\")\n",
        "    sample_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # サンプルタスク1\n",
        "    sample_task_1 = {\n",
        "        \"id\": \"0001\",\n",
        "        \"instruction\": \"T75フラスコに線維芽細胞を1本起こしてください\",\n",
        "        \"protocol\": {\n",
        "            \"steps\": [\n",
        "                {\"id\": 1, \"text\": \"15 mL遠沈管に9 mL、Dishに10 mL血清入り培地を入れて恒温槽、インキュベーターで温める\"},\n",
        "                {\"id\": 2, \"text\": \"液体窒素タンクから起こす細胞を素早く取り出す\"},\n",
        "                {\"id\": 3, \"text\": \"クライオチューブのキャップを少し緩め、再度閉める\"},\n",
        "                {\"id\": 4, \"text\": \"恒温槽でクライオチューブを温め、氷の塊がやや残るぐらいまで溶かす\"},\n",
        "                {\"id\": 5, \"text\": \"9 mLの温めた培地を一部移し、溶けた部分から遠沈管に戻す\"},\n",
        "                {\"id\": 6, \"text\": \"遠沈管の蓋をしっかり閉め、軽く転倒混和する\"},\n",
        "                {\"id\": 7, \"text\": \"1000 rpm、5 min、室温で遠心する\"},\n",
        "                {\"id\": 8, \"text\": \"上清を取り除き、Dishで温めた培地で懸濁する\"},\n",
        "                {\"id\": 9, \"text\": \"細胞懸濁液を培養器に播種する\"},\n",
        "                {\"id\": 10, \"text\": \"播種ムラができないように培養器を揺らし、静かにインキュベーターに入れる\"}\n",
        "            ]\n",
        "        },\n",
        "        \"resources\": {\n",
        "            \"aliases\": {\"Dish\": \"培養器\"},\n",
        "            \"mappings\": {\"Dish\": \"T75フラスコ\"},\n",
        "            \"constraints\": {\n",
        "                \"optional_steps\": [\n",
        "                    {\"name\": \"恒温槽の電源を消す\", \"earliest_index\": 7}\n",
        "                ]\n",
        "            }\n",
        "        },\n",
        "        \"ground_truth\": {\n",
        "            \"steps\": [\n",
        "                {\"id\": 1, \"text\": \"恒温槽の電源を入れる\"},\n",
        "                {\"id\": 2, \"text\": \"15 mL遠沈管に9 mL、T75フラスコに15 mL血清入り培地を入れる\"},\n",
        "                {\"id\": 3, \"text\": \"遠沈管は恒温槽、T75フラスコはインキュベーターに入れる\"},\n",
        "                {\"id\": 4, \"text\": \"液体窒素タンクから線維芽細胞のクライオチューブを取り出す\"},\n",
        "                {\"id\": 5, \"text\": \"クライオチューブのキャップを少し緩め、再度閉める\"},\n",
        "                {\"id\": 6, \"text\": \"恒温槽でクライオチューブを温め、氷の塊がやや残るぐらいまで溶かす\"},\n",
        "                {\"id\": 7, \"text\": \"遠沈管から、9 mLの温めた培地を一部移し、溶けた部分から遠沈管に戻す\"},\n",
        "                {\"id\": 8, \"text\": \"クライオチューブに培地を加えてピペッティングして、細胞を遠沈管に回収する\"},\n",
        "                {\"id\": 9, \"text\": \"遠沈管の蓋をしっかり閉め、軽く転倒混和する\"},\n",
        "                {\"id\": 10, \"text\": \"遠沈管を1000 rpm、5 min、室温で遠心する\"},\n",
        "                {\"id\": 11, \"text\": \"上清を取り除き、T75フラスコで温めた培地で懸濁する\"},\n",
        "                {\"id\": 12, \"text\": \"細胞懸濁液をT75フラスコに戻す\"},\n",
        "                {\"id\": 13, \"text\": \"播種ムラができないようにT75フラスコを揺らし、静かにインキュベーターに入れる\"},\n",
        "                {\"id\": 14, \"text\": \"恒温槽の電源を消す\"}\n",
        "            ]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # サンプルタスク2\n",
        "    sample_task_2 = {\n",
        "        \"id\": \"0002\",\n",
        "        \"instruction\": \"24ウェルプレートで細胞の培地交換を行ってください\",\n",
        "        \"protocol\": {\n",
        "            \"steps\": [\n",
        "                {\"id\": 1, \"text\": \"培地を恒温槽で温める\"},\n",
        "                {\"id\": 2, \"text\": \"プレートをインキュベーターから取り出す\"},\n",
        "                {\"id\": 3, \"text\": \"古い培地をアスピレーターで除去する\"},\n",
        "                {\"id\": 4, \"text\": \"新しい培地を各ウェルに加える\"},\n",
        "                {\"id\": 5, \"text\": \"プレートをインキュベーターに戻す\"}\n",
        "            ]\n",
        "        },\n",
        "        \"resources\": {\n",
        "            \"aliases\": {\"プレート\": \"培養プレート\"},\n",
        "            \"mappings\": {\"プレート\": \"24ウェルプレート\", \"培地\": \"DMEM培地\"},\n",
        "            \"constraints\": {}\n",
        "        },\n",
        "        \"ground_truth\": {\n",
        "            \"steps\": [\n",
        "                {\"id\": 1, \"text\": \"DMEM培地を恒温槽で37°Cに温める\"},\n",
        "                {\"id\": 2, \"text\": \"24ウェルプレートをインキュベーターから取り出す\"},\n",
        "                {\"id\": 3, \"text\": \"古い培地をアスピレーターで各ウェルから慎重に除去する\"},\n",
        "                {\"id\": 4, \"text\": \"新しいDMEM培地を各ウェルに1 mL加える\"},\n",
        "                {\"id\": 5, \"text\": \"24ウェルプレートをインキュベーターに戻す\"}\n",
        "            ]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # ファイルの保存\n",
        "    with open(sample_dir / \"task_0001.json\", 'w', encoding='utf-8') as f:\n",
        "        json.dump(sample_task_1, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    with open(sample_dir / \"task_0002.json\", 'w', encoding='utf-8') as f:\n",
        "        json.dump(sample_task_2, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"✅ サンプルデータを作成しました: {sample_dir}\")\n",
        "\n",
        "    # データ利用可能性を再チェック\n",
        "    availability = loader.check_data_availability()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WclvJVKH6z4Y",
        "outputId": "466f0e0a-b8e8-482c-8044-c03814799835"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📝 サンプルデータを作成中...\n",
            "✅ サンプルデータを作成しました: data/example/json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Pydanticモデルとプロンプトビルダー（Structured Outputs対応）\n",
        "#@title 7. データモデルとプロンプトビルダーの実装 { display-mode: \"form\" }\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Optional, Literal\n",
        "\n",
        "# Pydanticモデルの定義（Structured Outputs用）\n",
        "class ExperimentStepOutput(BaseModel):\n",
        "    \"\"\"実験手順の1ステップ\"\"\"\n",
        "    id: int = Field(description=\"ステップ番号\")\n",
        "    text: str = Field(description=\"実験手順の詳細な説明\")\n",
        "\n",
        "class ExperimentStepsOutput(BaseModel):\n",
        "    \"\"\"実験手順全体の出力\"\"\"\n",
        "    steps: List[ExperimentStepOutput] = Field(\n",
        "        description=\"実験手順のリスト\",\n",
        "        min_items=1\n",
        "    )\n",
        "\n",
        "    # オプション：メタデータ\n",
        "    total_steps: Optional[int] = Field(\n",
        "        default=None,\n",
        "        description=\"総ステップ数\"\n",
        "    )\n",
        "    estimated_time: Optional[str] = Field(\n",
        "        default=None,\n",
        "        description=\"推定所要時間\"\n",
        "    )\n",
        "    safety_notes: Optional[List[str]] = Field(\n",
        "        default=None,\n",
        "        description=\"安全上の注意事項\"\n",
        "    )\n",
        "\n",
        "# 代替の簡略版モデル（エラー時のフォールバック用）\n",
        "class SimpleStepsOutput(BaseModel):\n",
        "    \"\"\"シンプルな実験手順の出力\"\"\"\n",
        "    steps: List[ExperimentStepOutput]\n",
        "\n",
        "class PromptBuilder:\n",
        "    \"\"\"実験手順生成用のプロンプト構築クラス\"\"\"\n",
        "\n",
        "    def __init__(self, model_type: str = \"gpt-4o-mini\"):\n",
        "        self.model_type = model_type\n",
        "\n",
        "    def build_system_prompt(self) -> str:\n",
        "        \"\"\"システムプロンプトの構築\"\"\"\n",
        "        return \"\"\"あなたは生命科学実験の専門家です。\n",
        "与えられた実験指示、プロトコル、リソース情報から、実行可能な詳細な実験手順を生成してください。\n",
        "\n",
        "重要なルール：\n",
        "1. プロトコルのステップを基に、具体的な実験手順を作成する\n",
        "2. エイリアス（別名）を適切に解決し、正しい器具名・試薬名を使用する\n",
        "3. マッピング情報に従って、汎用的な記述を具体的な器具・条件に置き換える\n",
        "4. 制約条件を満たすように手順を調整する\n",
        "5. 必要に応じてステップを追加・修正・詳細化する\n",
        "6. 温度、時間、回転数などの数値は具体的に記載する\n",
        "7. 安全性と実験の成功に必要な暗黙的な手順も含める\n",
        "8. 各ステップは明確で実行可能な指示として記述する\"\"\"\n",
        "\n",
        "    def build_task_prompt(self, task: 'ExperimentTask') -> str:\n",
        "        \"\"\"タスク用のプロンプトを構築\"\"\"\n",
        "\n",
        "        prompt_parts = []\n",
        "\n",
        "        # 実験指示\n",
        "        prompt_parts.append(f\"【実験指示】\\n{task.instruction}\\n\")\n",
        "\n",
        "        # プロトコル\n",
        "        prompt_parts.append(\"【参照プロトコル】\")\n",
        "        for step in task.protocol:\n",
        "            prompt_parts.append(f\"{step.id}. {step.text}\")\n",
        "        prompt_parts.append(\"\")\n",
        "\n",
        "        # リソース情報\n",
        "        if task.resources.aliases:\n",
        "            prompt_parts.append(\"【エイリアス（別名）】\")\n",
        "            for key, value in task.resources.aliases.items():\n",
        "                prompt_parts.append(f\"- {key} = {value}\")\n",
        "            prompt_parts.append(\"\")\n",
        "\n",
        "        if task.resources.mappings:\n",
        "            prompt_parts.append(\"【マッピング（具体化）】\")\n",
        "            for key, value in task.resources.mappings.items():\n",
        "                prompt_parts.append(f\"- {key} → {value}\")\n",
        "            prompt_parts.append(\"\")\n",
        "\n",
        "        if task.resources.constraints:\n",
        "            prompt_parts.append(\"【制約条件】\")\n",
        "            if 'optional_steps' in task.resources.constraints:\n",
        "                for opt_step in task.resources.constraints['optional_steps']:\n",
        "                    prompt_parts.append(\n",
        "                        f\"- 「{opt_step['name']}」をステップ{opt_step['earliest_index']}以降に追加\"\n",
        "                    )\n",
        "            prompt_parts.append(\"\")\n",
        "\n",
        "        # タスク指示\n",
        "        prompt_parts.append(\"【タスク】\")\n",
        "        prompt_parts.append(\"上記の情報を基に、実行可能な詳細な実験手順を生成してください。\")\n",
        "        prompt_parts.append(\"以下の点に注意してください：\")\n",
        "        prompt_parts.append(\"1. エイリアスとマッピングを適用して具体的な器具名を使用\")\n",
        "        prompt_parts.append(\"2. 実験指示の要件を満たす\")\n",
        "        prompt_parts.append(\"3. 必要な準備手順（例：機器の電源ON）を追加\")\n",
        "        prompt_parts.append(\"4. 安全性と成功に必要な詳細を含める\")\n",
        "        prompt_parts.append(\"5. 制約条件で指定された追加ステップを適切な位置に挿入\")\n",
        "\n",
        "        return \"\\n\".join(prompt_parts)\n",
        "\n",
        "print(\"✅ Pydanticモデルとプロンプトビルダーを実装しました\")\n",
        "print(f\"   - ExperimentStepsOutput: {len(ExperimentStepsOutput.model_fields)}フィールド\")\n",
        "print(f\"   - SimpleStepsOutput: {len(SimpleStepsOutput.model_fields)}フィールド\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYc6bLUv7D5P",
        "outputId": "369fecd7-25c5-4d90-8aa3-f9d3beffbcaa"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Pydanticモデルとプロンプトビルダーを実装しました\n",
            "   - ExperimentStepsOutput: 4フィールド\n",
            "   - SimpleStepsOutput: 1フィールド\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: GPT実験手順生成器（Structured Outputs専用）\n",
        "#@title 8. GPT実験手順生成器（Structured Outputs版） { display-mode: \"form\" }\n",
        "\n",
        "class GPTExperimentGenerator:\n",
        "    \"\"\"GPTを使用した実験手順生成クラス（Structured Outputs専用）\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 model: str = \"gpt-5-mini-2025-08-07\", temperature: float=1.0):\n",
        "        self.client = OpenAI(api_key=API_KEY)\n",
        "        self.model = model\n",
        "        self.temperature = temperature\n",
        "        self.prompt_builder = PromptBuilder(model_type=model)\n",
        "        self.max_retries = 3  # パース失敗時の最大リトライ回数\n",
        "\n",
        "    def generate_steps(self, task: 'ExperimentTask') -> List[Dict]:\n",
        "        \"\"\"Structured Outputsを使用して実験手順を生成（リトライ機能付き）\"\"\"\n",
        "\n",
        "        # プロンプトの構築\n",
        "        system_prompt = self.prompt_builder.build_system_prompt()\n",
        "        user_prompt = self.prompt_builder.build_task_prompt(task)\n",
        "\n",
        "        last_error = None\n",
        "\n",
        "        for attempt in range(self.max_retries):\n",
        "            try:\n",
        "                logger.info(f\"実験手順生成中... (試行 {attempt + 1}/{self.max_retries})\")\n",
        "\n",
        "                completion = self.client.chat.completions.parse(\n",
        "                    model=self.model,\n",
        "                    messages=[\n",
        "                        {\"role\": \"system\", \"content\": system_prompt},\n",
        "                        {\"role\": \"user\", \"content\": user_prompt}\n",
        "                    ],\n",
        "                    response_format=ExperimentStepsOutput,\n",
        "                    temperature=self.temperature\n",
        "                )\n",
        "\n",
        "                parsed_output = completion.choices[0].message.parsed\n",
        "\n",
        "                if parsed_output and parsed_output.steps:\n",
        "                    steps = [\n",
        "                        {\"id\": step.id, \"text\": step.text}\n",
        "                        for step in parsed_output.steps\n",
        "                    ]\n",
        "                    if parsed_output.total_steps:\n",
        "                        logger.info(f\"総ステップ数: {parsed_output.total_steps}\")\n",
        "                    if parsed_output.estimated_time:\n",
        "                        logger.info(f\"推定時間: {parsed_output.estimated_time}\")\n",
        "                    if parsed_output.safety_notes:\n",
        "                        logger.info(f\"安全注意: {', '.join(parsed_output.safety_notes)}\")\n",
        "\n",
        "                    logger.info(f\"✅ 実験手順生成成功 (試行 {attempt + 1})\")\n",
        "                    return steps\n",
        "                else:\n",
        "                    logger.warning(f\"⚠️ パース失敗 (試行 {attempt + 1}/{self.max_retries}): 出力が空です\")\n",
        "                    last_error = \"Empty parsed output\"\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"⚠️ エラー発生 (試行 {attempt + 1}/{self.max_retries}): {str(e)}\")\n",
        "                last_error = e\n",
        "\n",
        "                if attempt < self.max_retries - 1:\n",
        "                    wait_time = 2 ** attempt\n",
        "                    logger.info(f\"⏳ {wait_time}秒待機後にリトライします...\")\n",
        "                    time.sleep(wait_time)\n",
        "\n",
        "        logger.error(f\"❌ {self.max_retries}回の試行すべてで実験手順生成に失敗しました\")\n",
        "        logger.error(f\"最後のエラー: {last_error}\")\n",
        "        self._log_generation_failure(task, last_error)\n",
        "\n",
        "        # すべての試行が失敗した場合、プロトコルをそのまま使用\n",
        "        fallback_steps = [\n",
        "            {\"id\": step.id, \"text\": step.text}\n",
        "            for step in task.protocol\n",
        "        ]\n",
        "        logger.warning(f\"⚠️ フォールバック: プロトコルをそのまま使用します（{len(fallback_steps)}ステップ）\")\n",
        "\n",
        "        return fallback_steps\n",
        "\n",
        "    def apply_resources(self, steps: List[Dict], task: 'ExperimentTask') -> List[Dict]:\n",
        "        \"\"\"リソース情報を適用して手順を修正\"\"\"\n",
        "\n",
        "        modified_steps = deepcopy(steps)\n",
        "\n",
        "        for step in modified_steps:\n",
        "            text = step.get('text', '')\n",
        "\n",
        "            # エイリアスの適用\n",
        "            for alias, actual in task.resources.aliases.items():\n",
        "                text = text.replace(alias, actual)\n",
        "\n",
        "            # マッピングの適用\n",
        "            for generic, specific in task.resources.mappings.items():\n",
        "                actual_generic = task.resources.aliases.get(generic, generic)\n",
        "                text = text.replace(actual_generic, specific)\n",
        "\n",
        "            step['text'] = text\n",
        "\n",
        "        if 'optional_steps' in task.resources.constraints:\n",
        "            for opt_step in task.resources.constraints['optional_steps']:\n",
        "                insert_pos = opt_step['earliest_index']\n",
        "                new_step = {\n",
        "                    'id': insert_pos,\n",
        "                    'text': opt_step['name']\n",
        "                }\n",
        "\n",
        "                # 適切な位置に挿入\n",
        "                if insert_pos <= len(modified_steps):\n",
        "                    modified_steps.insert(insert_pos - 1, new_step)\n",
        "                else:\n",
        "                    modified_steps.append(new_step)\n",
        "\n",
        "            # IDの再割り当て\n",
        "            for i, step in enumerate(modified_steps, 1):\n",
        "                step['id'] = i\n",
        "\n",
        "        return modified_steps\n",
        "\n",
        "    def _log_generation_failure(self, task: 'ExperimentTask', error: Any):\n",
        "        \"\"\"生成失敗をログファイルに記録\"\"\"\n",
        "\n",
        "        log_dir = Path(\"./outputs/logs\")\n",
        "        log_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        log_file = log_dir / f\"generation_failure_{task.id}_{timestamp}.json\"\n",
        "\n",
        "        log_data = {\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            \"task_id\": task.id,\n",
        "            \"instruction\": task.instruction,\n",
        "            \"model\": self.model,\n",
        "            \"error\": str(error),\n",
        "            \"protocol_steps\": len(task.protocol),\n",
        "            \"has_ground_truth\": task.ground_truth is not None\n",
        "        }\n",
        "\n",
        "        with open(log_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(log_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        logger.info(f\"📝 エラーログを保存: {log_file}\")\n",
        "\n",
        "print(\"✅ Structured Outputs専用のGPT実験手順生成器を実装しました\")\n",
        "print(\"デフォルト設定：\")\n",
        "print(\"   - モデル: gpt-5-mini-2025-08-07\")\n",
        "print(\"   - 最大リトライ回数: 3\")\n",
        "print(\"   - エラーログ: ./outputs/logs/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXgbS-9P7jYt",
        "outputId": "af5f815e-894a-4916-f86b-f542aaac9169"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Structured Outputs専用のGPT実験手順生成器を実装しました\n",
            "デフォルト設定：\n",
            "   - モデル: gpt-5-mini-2025-08-07\n",
            "   - 最大リトライ回数: 3\n",
            "   - エラーログ: ./outputs/logs/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: LLMベースの評価システム（5点満点版）\n",
        "#@title 9. LLMベースの評価システム { display-mode: \"form\" }\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Optional, Dict\n",
        "\n",
        "# 個別評価項目の結果\n",
        "class CriterionScore(BaseModel):\n",
        "    \"\"\"個別評価項目のスコア\"\"\"\n",
        "    name: str = Field(description=\"評価項目名\")\n",
        "    score: int = Field(description=\"スコア（1-5）\", ge=1, le=5)\n",
        "    reasoning: str = Field(description=\"スコアの根拠\")\n",
        "\n",
        "# 減点項目\n",
        "class Deduction(BaseModel):\n",
        "    \"\"\"減点項目\"\"\"\n",
        "    reason: str = Field(description=\"減点理由\")\n",
        "    points: float = Field(description=\"減点数\", ge=0)\n",
        "    examples: List[str] = Field(default_factory=list, description=\"該当箇所\")\n",
        "\n",
        "# 評価結果\n",
        "class EvaluationResult(BaseModel):\n",
        "    \"\"\"実験手順の評価結果\"\"\"\n",
        "    task_id: str\n",
        "\n",
        "    # 基本評価（各5点満点）\n",
        "    completeness: CriterionScore = Field(description=\"必要な要素がすべて含まれているか\")\n",
        "    specificity: CriterionScore = Field(description=\"数値や条件が明確か\")\n",
        "    consistency: CriterionScore = Field(description=\"矛盾がなく論理的か\")\n",
        "    safety: CriterionScore = Field(description=\"安全上の配慮が適切か\")\n",
        "    feasibility: CriterionScore = Field(description=\"実際に実行可能か\")\n",
        "    clarity: CriterionScore = Field(description=\"理解しやすく曖昧さがないか\")\n",
        "\n",
        "    # 減点\n",
        "    deductions: List[Deduction] = Field(default_factory=list)\n",
        "\n",
        "    # 総合評価\n",
        "    raw_score: float = Field(description=\"減点前の平均スコア\")\n",
        "    final_score: float = Field(description=\"減点後の最終スコア（1-5）\")\n",
        "    feedback: str = Field(description=\"総合フィードバック\")\n",
        "    improvements: List[str] = Field(default_factory=list, description=\"改善提案\")\n",
        "\n",
        "class LLMEvaluator:\n",
        "    \"\"\"LLMベースの実験手順評価クラス\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 model: str = \"gpt-5-mini-2025-08-07\",\n",
        "                 temperature: float = 1.0):\n",
        "        self.client = OpenAI(api_key=API_KEY)\n",
        "        self.model = model\n",
        "        self.temperature = temperature\n",
        "        self.max_retries = 2\n",
        "\n",
        "    def evaluate(self,\n",
        "                task: 'ExperimentTask',\n",
        "                generated_steps: List[Dict]) -> EvaluationResult:\n",
        "        \"\"\"実験手順を評価\"\"\"\n",
        "\n",
        "        system_prompt = self._build_system_prompt()\n",
        "        user_prompt = self._build_user_prompt(task, generated_steps)\n",
        "\n",
        "        for attempt in range(self.max_retries):\n",
        "            try:\n",
        "                logger.info(f\"評価実行中... (試行 {attempt + 1}/{self.max_retries})\")\n",
        "\n",
        "                completion = self.client.chat.completions.parse(\n",
        "                    model=self.model,\n",
        "                    messages=[\n",
        "                        {\"role\": \"system\", \"content\": system_prompt},\n",
        "                        {\"role\": \"user\", \"content\": user_prompt}\n",
        "                    ],\n",
        "                    response_format=EvaluationResult,\n",
        "                    temperature=self.temperature\n",
        "                )\n",
        "\n",
        "                result = completion.choices[0].message.parsed\n",
        "                if result:\n",
        "                    result = self._calculate_final_score(result)\n",
        "                    logger.info(f\"✅ 評価完了: {result.final_score:.2f}/5.0\")\n",
        "                    return result\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"⚠️ 評価エラー (試行 {attempt + 1}): {str(e)}\")\n",
        "                if attempt < self.max_retries - 1:\n",
        "                    time.sleep(2)\n",
        "\n",
        "        logger.error(\"❌ 評価に失敗しました\")\n",
        "        return self._create_default_evaluation(task.id, len(generated_steps))\n",
        "\n",
        "    def _build_system_prompt(self) -> str:\n",
        "        \"\"\"評価用システムプロンプト\"\"\"\n",
        "        return \"\"\"あなたは生命科学実験の専門家です。実験手順を以下の基準で評価してください。\n",
        "\n",
        "【採点基準（5点満点）】\n",
        "1点: 誤っている／要件を満たしていない\n",
        "2点: 誤っているが、方向性は合っている\n",
        "3点: 部分的に正しい\n",
        "4点: 正しい／要件を満たしている\n",
        "5点: 優れている／非常に実用的\n",
        "\n",
        "【評価項目】\n",
        "1. 完全性: 必要な器具、試薬、手順がすべて含まれているか\n",
        "2. 具体性: 温度、時間、量などが具体的な数値で示されているか\n",
        "3. 一貫性: 手順間で矛盾がなく論理的か\n",
        "4. 安全性: 安全上の配慮が適切か\n",
        "5. 実行可能性: 実際のラボで実行可能か\n",
        "6. 明確性: 指示が明確で理解しやすいか\n",
        "\n",
        "【減点項目】\n",
        "- 不自然な日本語: -1点\n",
        "- 事実と異なる記述: -1点\n",
        "- 過度な安全性: 2点に固定\n",
        "- 単位の欠落: -0.5点\n",
        "- 曖昧な表現: -0.5点\n",
        "\n",
        "各項目を採点し、根拠を説明してください。\n",
        "減点項目があれば具体例とともに記載してください。\"\"\"\n",
        "\n",
        "    def _build_user_prompt(self,\n",
        "                          task: 'ExperimentTask',\n",
        "                          generated_steps: List[Dict]) -> str:\n",
        "        \"\"\"評価用ユーザープロンプト\"\"\"\n",
        "\n",
        "        prompt_parts = []\n",
        "\n",
        "        prompt_parts.append(f\"【タスク】{task.instruction}\\n\")\n",
        "\n",
        "        prompt_parts.append(\"【生成された手順】\")\n",
        "        for step in generated_steps:\n",
        "            prompt_parts.append(f\"{step['id']}. {step['text']}\")\n",
        "        prompt_parts.append(\"\")\n",
        "\n",
        "        prompt_parts.append(\"【元のプロトコル】\")\n",
        "        for step in task.protocol:\n",
        "            prompt_parts.append(f\"{step.id}. {step.text}\")\n",
        "        prompt_parts.append(\"\")\n",
        "\n",
        "        if task.resources.aliases or task.resources.mappings:\n",
        "            prompt_parts.append(\"【リソース情報】\")\n",
        "            if task.resources.aliases:\n",
        "                for k, v in task.resources.aliases.items():\n",
        "                    prompt_parts.append(f\"  {k} = {v}\")\n",
        "            if task.resources.mappings:\n",
        "                for k, v in task.resources.mappings.items():\n",
        "                    prompt_parts.append(f\"  {k} → {v}\")\n",
        "            prompt_parts.append(\"\")\n",
        "\n",
        "        prompt_parts.append(\"上記の実験手順を6つの項目で評価し、減点項目をチェックしてください。\")\n",
        "\n",
        "        return \"\\n\".join(prompt_parts)\n",
        "\n",
        "    def _calculate_final_score(self, result: EvaluationResult) -> EvaluationResult:\n",
        "        \"\"\"最終スコアを計算\"\"\"\n",
        "\n",
        "        # 基本スコアの平均\n",
        "        scores = [\n",
        "            result.completeness.score,\n",
        "            result.specificity.score,\n",
        "            result.consistency.score,\n",
        "            result.safety.score,\n",
        "            result.feasibility.score,\n",
        "            result.clarity.score\n",
        "        ]\n",
        "        result.raw_score = sum(scores) / len(scores)\n",
        "\n",
        "        # 減点適用\n",
        "        total_deduction = 0\n",
        "        for deduction in result.deductions:\n",
        "            if \"過度な安全性\" in deduction.reason:\n",
        "                result.final_score = 2.0\n",
        "                return result\n",
        "            total_deduction += deduction.points\n",
        "\n",
        "        result.final_score = max(1.0, result.raw_score - total_deduction)\n",
        "        return result\n",
        "\n",
        "    def _create_default_evaluation(self, task_id: str, num_steps: int) -> EvaluationResult:\n",
        "        \"\"\"デフォルト評価\"\"\"\n",
        "\n",
        "        default = CriterionScore(\n",
        "            name=\"default\",\n",
        "            score=3,\n",
        "            reasoning=\"評価失敗のため中間値を使用\"\n",
        "        )\n",
        "\n",
        "        return EvaluationResult(\n",
        "            task_id=task_id,\n",
        "            completeness=default,\n",
        "            specificity=default,\n",
        "            consistency=default,\n",
        "            safety=default,\n",
        "            feasibility=default,\n",
        "            clarity=default,\n",
        "            deductions=[],\n",
        "            raw_score=3.0,\n",
        "            final_score=3.0,\n",
        "            feedback=\"評価を完了できませんでした\",\n",
        "            improvements=[]\n",
        "        )\n",
        "\n",
        "    def create_summary(self, results: List[EvaluationResult]) -> pd.DataFrame:\n",
        "        \"\"\"評価結果のサマリー作成\"\"\"\n",
        "\n",
        "        data = []\n",
        "        for r in results:\n",
        "            data.append({\n",
        "                'task_id': r.task_id,\n",
        "                'completeness': r.completeness.score,\n",
        "                'specificity': r.specificity.score,\n",
        "                'consistency': r.consistency.score,\n",
        "                'safety': r.safety.score,\n",
        "                'feasibility': r.feasibility.score,\n",
        "                'clarity': r.clarity.score,\n",
        "                'deductions': len(r.deductions),\n",
        "                'final_score': r.final_score\n",
        "            })\n",
        "\n",
        "        return pd.DataFrame(data)\n",
        "\n",
        "print(\"✅ 評価システムを実装しました\")\n",
        "print(\"  - 5点満点評価\")\n",
        "print(\"  - 6つの評価項目\")\n",
        "print(\"  - 自動減点機能\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifjqbRoeFXgt",
        "outputId": "bce58e2a-6ea4-4a72-ca1e-436d55bb5683"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 評価システムを実装しました\n",
            "  - 5点満点評価\n",
            "  - 6つの評価項目\n",
            "  - 自動減点機能\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: メインパイプライン（評価システム統合版）\n",
        "#@title 10. メインパイプライン { display-mode: \"form\" }\n",
        "\n",
        "import uuid\n",
        "from datetime import datetime\n",
        "import shutil\n",
        "\n",
        "\n",
        "class RunManager:\n",
        "    \"\"\"実行ごとの結果管理クラス\"\"\"\n",
        "\n",
        "    def __init__(self, base_dir: str = \"./outputs\"):\n",
        "        self.base_dir = Path(base_dir)\n",
        "        self.runs_dir = self.base_dir / \"runs\"\n",
        "        self.runs_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # 実行IDの生成（タイムスタンプ + 短いUUID）\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        short_id = str(uuid.uuid4())[:4]\n",
        "        self.run_id = f\"{timestamp}_{short_id}\"\n",
        "\n",
        "        self.run_dir = self.runs_dir / self.run_id\n",
        "        self.run_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        (self.run_dir / \"evaluations\").mkdir(exist_ok=True)\n",
        "        (self.run_dir / \"logs\").mkdir(exist_ok=True)\n",
        "\n",
        "        logger.info(f\"📁 実行ID: {self.run_id}\")\n",
        "        logger.info(f\"📁 結果保存先: {self.run_dir}\")\n",
        "\n",
        "        # 実行履歴の更新\n",
        "        self._update_run_history()\n",
        "\n",
        "    def save_config(self, config: Dict):\n",
        "        config_file = self.run_dir / \"config.json\"\n",
        "        config_data = {\n",
        "            \"run_id\": self.run_id,\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            **config\n",
        "        }\n",
        "        with open(config_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(config_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    def get_path(self, filename: str) -> Path:\n",
        "        return self.run_dir / filename\n",
        "\n",
        "    def update_latest(self):\n",
        "        \"\"\"最新実行フォルダを更新\"\"\"\n",
        "        latest_dir = self.base_dir / \"latest\"\n",
        "\n",
        "        # 既存のlatestディレクトリを削除\n",
        "        if latest_dir.exists():\n",
        "            shutil.rmtree(latest_dir)\n",
        "\n",
        "        # 現在の実行内容をlatestにコピー\n",
        "        shutil.copytree(self.run_dir, latest_dir)\n",
        "\n",
        "        logger.info(f\"📁 最新結果を更新: {latest_dir}\")\n",
        "\n",
        "    def _update_run_history(self):\n",
        "        \"\"\"実行履歴を更新\"\"\"\n",
        "        history_file = self.base_dir / \"run_history.json\"\n",
        "\n",
        "        # 既存の履歴を読み込み\n",
        "        if history_file.exists():\n",
        "            with open(history_file, 'r', encoding='utf-8') as f:\n",
        "                history = json.load(f)\n",
        "        else:\n",
        "            history = {\"runs\": []}\n",
        "\n",
        "        # 新しい実行を追加\n",
        "        history[\"runs\"].append({\n",
        "            \"run_id\": self.run_id,\n",
        "            \"start_time\": datetime.now().isoformat(),\n",
        "            \"status\": \"running\"\n",
        "        })\n",
        "\n",
        "        # 保存\n",
        "        with open(history_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(history, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    def finalize(self, status: str = \"completed\", summary: Dict = None):\n",
        "        \"\"\"実行を完了\"\"\"\n",
        "        history_file = self.base_dir / \"run_history.json\"\n",
        "\n",
        "        if history_file.exists():\n",
        "            with open(history_file, 'r', encoding='utf-8') as f:\n",
        "                history = json.load(f)\n",
        "\n",
        "            # 該当する実行を更新\n",
        "            for run in history[\"runs\"]:\n",
        "                if run[\"run_id\"] == self.run_id:\n",
        "                    run[\"status\"] = status\n",
        "                    run[\"end_time\"] = datetime.now().isoformat()\n",
        "                    if summary:\n",
        "                        run[\"summary\"] = summary\n",
        "                    break\n",
        "\n",
        "            with open(history_file, 'w', encoding='utf-8') as f:\n",
        "                json.dump(history, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        # 最新フォルダを更新\n",
        "        self.update_latest()\n",
        "\n",
        "        logger.info(f\"✅ 実行完了: {self.run_id} ({status})\")\n",
        "\n",
        "\n",
        "class ExperimentPipeline:\n",
        "    \"\"\"実験手順生成と評価のメインパイプライン\"\"\"\n",
        "\n",
        "    def __init__(self, model: str = \"gpt-5-mini-2025-08-07\", temperature: float= 1.0):\n",
        "        if not API_KEY:\n",
        "            raise ValueError(\"APIキーが設定されていません\")\n",
        "        self.gpt_generator = GPTExperimentGenerator(model=model, temperature=temperature)\n",
        "        self.llm_evaluator = LLMEvaluator(model=model, temperature=temperature)\n",
        "        self.data_loader = DataLoader()\n",
        "        self.run_manager = RunManager()\n",
        "\n",
        "        # 設定を保存\n",
        "        self.run_manager.save_config({\n",
        "            \"model\": model,\n",
        "            \"temperature\": temperature,\n",
        "            \"generator\": \"structured_outputs\",\n",
        "            \"evaluator\": \"llm_5point\"\n",
        "        })\n",
        "\n",
        "        logger.info(f\"✅ Pipeline initialized with model: {model}, temperature: {temperature}\")\n",
        "\n",
        "    def process_task(self, task: 'ExperimentTask') -> Dict:\n",
        "        \"\"\"単一タスクの処理（生成＋評価）\"\"\"\n",
        "\n",
        "        logger.info(f\"🔬 Processing task {task.id}: {task.instruction[:50]}...\")\n",
        "        # 手順生成\n",
        "        generated_steps = self.gpt_generator.generate_steps(task)\n",
        "        # リソース適用\n",
        "        generated_steps = self.gpt_generator.apply_resources(generated_steps, task)\n",
        "        # LLM評価\n",
        "        evaluation = self.llm_evaluator.evaluate(task, generated_steps)\n",
        "\n",
        "        logger.info(f\"📊 評価スコア: {evaluation.final_score:.2f}/5.0\")\n",
        "\n",
        "        result = {\n",
        "            'task_id': task.id,\n",
        "            'instruction': task.instruction,\n",
        "            'generated_steps': generated_steps,\n",
        "            'evaluation': evaluation,\n",
        "            'timestamp': datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "        return result\n",
        "\n",
        "    def process_dataset(self,\n",
        "                       dataset_type: str = \"example\",\n",
        "                       save_results: bool = True) -> Tuple[pd.DataFrame, List[Dict]]:\n",
        "        \"\"\"データセット全体の処理\"\"\"\n",
        "\n",
        "        tasks = self.data_loader.load_dataset(dataset_type)\n",
        "        if not tasks:\n",
        "            logger.error(f\"❌ No tasks found in {dataset_type} dataset\")\n",
        "            self.run_manager.finalize(\n",
        "                status=\"failed\",\n",
        "                summary={\"error\": \"No tasks found\"})\n",
        "            return pd.DataFrame(), []\n",
        "\n",
        "        logger.info(f\"📚 Processing {len(tasks)} tasks from {dataset_type} dataset\")\n",
        "\n",
        "        self.run_manager.save_config({\n",
        "            \"dataset_type\": dataset_type,\n",
        "            \"num_tasks\": len(tasks)\n",
        "        })\n",
        "\n",
        "        results = []\n",
        "        evaluations = []\n",
        "\n",
        "        # 各タスクを処理\n",
        "        for task in tqdm(tasks, desc=f\"Processing {dataset_type} dataset\"):\n",
        "            try:\n",
        "                result = self.process_task(task)\n",
        "                results.append(result)\n",
        "                evaluations.append(result['evaluation'])\n",
        "\n",
        "                # 個別結果を即座に保存\n",
        "                if save_results:\n",
        "                    eval_file = self.run_manager.get_path(f\"evaluations/{task.id}.json\")\n",
        "                    with open(eval_file, 'w', encoding='utf-8') as f:\n",
        "                        json.dump({\n",
        "                            'task_id': result['task_id'],\n",
        "                            'instruction': result['instruction'],\n",
        "                            'num_steps': len(result['generated_steps']),\n",
        "                            'evaluation': result['evaluation'].model_dump()\n",
        "                        }, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Task {task.id} failed: {e}\")\n",
        "                # エラーもログに記録\n",
        "                error_file = self.run_manager.get_path(f\"logs/error_{task.id}.txt\")\n",
        "                with open(error_file, 'w') as f:\n",
        "                    f.write(str(e))\n",
        "\n",
        "            # レート制限対策\n",
        "            time.sleep(1)\n",
        "\n",
        "        # 結果の保存\n",
        "        if save_results:\n",
        "            self._save_results(results, dataset_type)\n",
        "\n",
        "        # 評価サマリーの作成\n",
        "        summary_df = self.llm_evaluator.create_summary(evaluations)\n",
        "\n",
        "        # サマリーをCSVで保存\n",
        "        if not summary_df.empty:\n",
        "            summary_file = self.run_manager.get_path(\"summary.csv\")\n",
        "            summary_df.to_csv(summary_file, index=False)\n",
        "\n",
        "            # 実行完了\n",
        "            self.run_manager.finalize(status=\"completed\", summary={\n",
        "                \"num_tasks\": len(tasks),\n",
        "                \"num_completed\": len(results),\n",
        "                \"avg_score\": summary_df['final_score'].mean(),\n",
        "                \"dataset_type\": dataset_type\n",
        "            })\n",
        "\n",
        "        return summary_df, results\n",
        "\n",
        "    def _save_results(self, results: List[Dict], dataset_type: str):\n",
        "        \"\"\"結果の保存\"\"\"\n",
        "\n",
        "        # リーダーボード提出形式\n",
        "        submission = {\n",
        "            'team_name': 'baseline',\n",
        "            'submission_time': datetime.now().isoformat(),\n",
        "            'dataset_type': dataset_type,\n",
        "            'model': self.gpt_generator.model,\n",
        "            'predictions': []\n",
        "        }\n",
        "\n",
        "        for result in results:\n",
        "            submission['predictions'].append({\n",
        "                'task_id': result['task_id'],\n",
        "                'steps': result['generated_steps']\n",
        "            })\n",
        "\n",
        "        submission_file = self.run_manager.get_path(\"submission.json\")\n",
        "        with open(submission_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(submission, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        logger.info(f\"💾 Submission saved to {submission_file}\")\n",
        "\n",
        "print(\"✅ 実行管理機能付きメインパイプラインを実装しました\")\n",
        "print(\"特徴:\")\n",
        "print(\"  - 実行ごとに一意のフォルダ（YYYYMMDD_HHMMSS_ID）\")\n",
        "print(\"  - 実行設定の自動保存\")\n",
        "print(\"  - 最新実行へのアクセス（latest/）\")\n",
        "print(\"  - 実行履歴の管理（run_history.json）\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efdCpfUVFiKn",
        "outputId": "bd6ed009-71f8-4d3d-8d2a-a2daefd11b0c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 実行管理機能付きメインパイプラインを実装しました\n",
            "特徴:\n",
            "  - 実行ごとに一意のフォルダ（YYYYMMDD_HHMMSS_ID）\n",
            "  - 実行設定の自動保存\n",
            "  - 最新実行へのアクセス（latest/）\n",
            "  - 実行履歴の管理（run_history.json）\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 11: 実行\n",
        "#@title 11. ベースライン実行 { run: \"auto\" }\n",
        "#@markdown 以下の設定でベースライン手法を実行します\n",
        "\n",
        "dataset_type = \"example\" #@param [\"example\", \"public\", \"private\"]\n",
        "save_results = True #@param {type:\"boolean\"}\n",
        "model_name = \"gpt-5-mini-2025-08-07\" #@param [\"gpt-4.1-mini-2025-04-14\", \"gpt-4o-2024-08-06\", \"gpt-5-2025-08-07\", \"gpt-5-mini-2025-08-07\", \"gpt-5-nano-2025-08-07\"]\n",
        "#@markdown gpt-4o-mini, gpt-4o-2024-08-06, あるいはそれ以降のモデルに対応しています。<br>\n",
        "#@markdown (Structured outputを使用しているため) <br>\n",
        "#@markdown gpt-5系モデルを使用する場合、temperature=1.0としてください。\n",
        "temperature = 1.0 #@param\n",
        "\n",
        "if not API_KEY:\n",
        "    print(\"❌ APIキーが設定されていません\")\n",
        "    print(\"Cell 2でAPIキーを設定してください\")\n",
        "\n",
        "else:\n",
        "    print(\"=\"*60)\n",
        "    print(\"🚀 LA-Bench 2025 Baseline Execution\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Dataset: {dataset_type}\")\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(f\"Temperature: {temperature}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # パイプラインの初期化と実行\n",
        "    pipeline = ExperimentPipeline(model=model_name, temperature=temperature)\n",
        "    summary_df, results = pipeline.process_dataset(\n",
        "        dataset_type=dataset_type,\n",
        "        save_results=save_results\n",
        "    )\n",
        "\n",
        "    # 結果の表示\n",
        "    if not summary_df.empty:\n",
        "        print(\"\\n📊 評価結果サマリー（5点満点）\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # 各タスクの評価\n",
        "        print(\"\\n【タスク別評価】\")\n",
        "        display_cols = ['task_id', 'final_score', 'completeness', 'specificity',\n",
        "                        'consistency', 'safety', 'feasibility', 'clarity']\n",
        "        print(summary_df[display_cols].to_string(index=False))\n",
        "\n",
        "        # 統計情報\n",
        "        print(\"\\n【統計情報】\")\n",
        "        print(f\"タスク数: {len(summary_df)}\")\n",
        "        print(f\"平均スコア: {summary_df['final_score'].mean():.2f}/5.0\")\n",
        "        print(f\"最高スコア: {summary_df['final_score'].max():.2f}/5.0\")\n",
        "        print(f\"最低スコア: {summary_df['final_score'].min():.2f}/5.0\")\n",
        "        print(f\"標準偏差: {summary_df['final_score'].std():.2f}\")\n",
        "\n",
        "        # 評価項目別の平均\n",
        "        print(\"\\n【評価項目別平均スコア】\")\n",
        "        criteria = ['completeness', 'specificity', 'consistency',\n",
        "                    'safety', 'feasibility', 'clarity']\n",
        "        for criterion in criteria:\n",
        "            avg_score = summary_df[criterion].mean()\n",
        "            print(f\"  {criterion:12s}: {avg_score:.2f}/5.0\")\n",
        "\n",
        "        # 減点の統計\n",
        "        if 'deductions' in summary_df.columns:\n",
        "            total_deductions = summary_df['deductions'].sum()\n",
        "            if total_deductions > 0:\n",
        "                print(f\"\\n【減点統計】\")\n",
        "                print(f\"  総減点項目数: {total_deductions}\")\n",
        "                print(f\"  減点があったタスク: {(summary_df['deductions'] > 0).sum()}/{len(summary_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639,
          "referenced_widgets": [
            "b40ac992b90b4aaa88a76bfdfbdac9c2",
            "97a08cebeac54ab09f411be9aba92df7",
            "44cf68d6ead14da0aa7728d2dcd62dea",
            "04780b69229e4843b6afe0749eea65f0",
            "2f63e788f9cb4cee8c5f7a1bf3493dc2",
            "c82338319c7243c2b140cab742e6cbf6",
            "f35d254373ad43c9b9286d6f09c60cce",
            "59189fe39e3d4138ac6b2827be7c62e6",
            "cb000000b4984fba9929e157d7325495",
            "56626730a9a546908e25dee10e500ba3",
            "ef88243320c44924ac5e804ffee3069b"
          ]
        },
        "cellView": "form",
        "id": "tdc_5sgoKtPi",
        "outputId": "6cedb83b-cadf-4b4b-b51a-4921a10e73d5"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "🚀 LA-Bench 2025 Baseline Execution\n",
            "============================================================\n",
            "Dataset: example\n",
            "Model: gpt-5-mini-2025-08-07\n",
            "Temperature: 1.0\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing example dataset:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b40ac992b90b4aaa88a76bfdfbdac9c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 評価結果サマリー（5点満点）\n",
            "============================================================\n",
            "\n",
            "【タスク別評価】\n",
            "                  task_id  final_score  completeness  specificity  consistency  safety  feasibility  clarity\n",
            "T75_fibroblast_thawing_v1     2.000000             4            3            3       4            4        3\n",
            "                 task_001     2.333333             4            4            3       5            4        3\n",
            "\n",
            "【統計情報】\n",
            "タスク数: 2\n",
            "平均スコア: 2.17/5.0\n",
            "最高スコア: 2.33/5.0\n",
            "最低スコア: 2.00/5.0\n",
            "標準偏差: 0.24\n",
            "\n",
            "【評価項目別平均スコア】\n",
            "  completeness: 4.00/5.0\n",
            "  specificity : 3.50/5.0\n",
            "  consistency : 3.00/5.0\n",
            "  safety      : 4.50/5.0\n",
            "  feasibility : 4.00/5.0\n",
            "  clarity     : 3.00/5.0\n",
            "\n",
            "【減点統計】\n",
            "  総減点項目数: 4\n",
            "  減点があったタスク: 2/2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: 結果の可視化と分析\n",
        "#@title 12. 結果の可視化と分析 { display-mode: \"form\" }\n",
        "\n",
        "import numpy as np\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "if 'summary_df' in locals() and not summary_df.empty:\n",
        "    print(\"=\"*60)\n",
        "    print(\"📊 LA-Bench 2025 評価結果分析\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # 1. 全体パフォーマンス\n",
        "    print(\"\\n【全体パフォーマンス】\")\n",
        "    mean_score = summary_df['final_score'].mean()\n",
        "    std_score = summary_df['final_score'].std()\n",
        "    ci_95 = 1.96 * std_score / np.sqrt(len(summary_df))\n",
        "\n",
        "    print(f\"  最終スコア: {mean_score:.2f} ± {ci_95:.2f} (95% CI)\")\n",
        "    print(f\"  中央値: {summary_df['final_score'].median():.2f}\")\n",
        "    print(f\"  四分位範囲: [{summary_df['final_score'].quantile(0.25):.2f}, {summary_df['final_score'].quantile(0.75):.2f}]\")\n",
        "\n",
        "    # パフォーマンス判定\n",
        "    if mean_score >= 4.0:\n",
        "        grade = \"🏆 優秀\"\n",
        "    elif mean_score >= 3.5:\n",
        "        grade = \"✅ 良好\"\n",
        "    elif mean_score >= 3.0:\n",
        "        grade = \"📈 改善余地あり\"\n",
        "    else:\n",
        "        grade = \"⚠️ 要改善\"\n",
        "    print(f\"  判定: {grade}\")\n",
        "\n",
        "    # 2. スコア分布の詳細分析\n",
        "    print(\"\\n【スコア分布】\")\n",
        "    hist_data = []\n",
        "    for i in range(1, 6):\n",
        "        if i == 5:\n",
        "            count = (summary_df['final_score'] == i).sum()\n",
        "        else:\n",
        "            count = ((summary_df['final_score'] >= i) & (summary_df['final_score'] < i+1)).sum()\n",
        "        pct = count / len(summary_df) * 100\n",
        "        bar = \"█\" * int(pct / 2)\n",
        "        hist_data.append(f\"  [{i}]: {count:3d} ({pct:5.1f}%) {bar}\")\n",
        "    for line in hist_data:\n",
        "        print(line)\n",
        "\n",
        "    # 3. 評価項目の強み・弱み分析\n",
        "    criteria = ['completeness', 'specificity', 'consistency',\n",
        "               'safety', 'feasibility', 'clarity']\n",
        "    available = [c for c in criteria if c in summary_df.columns]\n",
        "\n",
        "    if available:\n",
        "        print(\"\\n【評価項目分析】\")\n",
        "        criteria_stats = []\n",
        "        for c in available:\n",
        "            mean = summary_df[c].mean()\n",
        "            std = summary_df[c].std()\n",
        "            criteria_stats.append((c, mean, std))\n",
        "\n",
        "        # ソートして表示\n",
        "        criteria_stats.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        print(\"  強み（上位3項目）:\")\n",
        "        for c, mean, std in criteria_stats[:3]:\n",
        "            indicator = \"◆\" * int(mean)\n",
        "            print(f\"    {c:12s}: {mean:.2f}±{std:.2f} {indicator}\")\n",
        "\n",
        "        print(\"  弱み（下位3項目）:\")\n",
        "        for c, mean, std in criteria_stats[-3:]:\n",
        "            indicator = \"◇\" * int(5 - mean)\n",
        "            print(f\"    {c:12s}: {mean:.2f}±{std:.2f} {indicator}\")\n",
        "\n",
        "        # 改善優先度（標準偏差が大きく平均が低い）\n",
        "        priority = sorted(criteria_stats, key=lambda x: -x[2] * (5 - x[1]))\n",
        "        print(f\"  最優先改善項目: {priority[0][0]} (不安定かつ低スコア)\")\n",
        "\n",
        "    # 4. 減点パターン分析\n",
        "    if 'deductions' in summary_df.columns:\n",
        "        total_deductions = summary_df['deductions'].sum()\n",
        "        if total_deductions > 0:\n",
        "            print(\"\\n【減点分析】\")\n",
        "            no_deduction = (summary_df['deductions'] == 0).sum()\n",
        "            with_deduction = (summary_df['deductions'] > 0).sum()\n",
        "            print(f\"  減点なし: {no_deduction} ({no_deduction/len(summary_df)*100:.1f}%)\")\n",
        "            print(f\"  減点あり: {with_deduction} ({with_deduction/len(summary_df)*100:.1f}%)\")\n",
        "\n",
        "            # 減点の影響度\n",
        "            if with_deduction > 0:\n",
        "                impact = (summary_df[summary_df['deductions'] == 0]['final_score'].mean() -\n",
        "                         summary_df[summary_df['deductions'] > 0]['final_score'].mean())\n",
        "                print(f\"  減点による平均スコア低下: -{impact:.2f}\")\n",
        "\n",
        "    # 5. 外れ値とリスクタスク\n",
        "    print(\"\\n【要注意タスク】\")\n",
        "    threshold = mean_score - 2 * std_score\n",
        "    outliers = summary_df[summary_df['final_score'] < threshold]\n",
        "    if len(outliers) > 0:\n",
        "        print(f\"  外れ値タスク（< {threshold:.2f}）: {len(outliers)}件\")\n",
        "        for _, row in outliers.head(3).iterrows():\n",
        "            print(f\"    - {row['task_id']}: {row['final_score']:.2f}\")\n",
        "    else:\n",
        "        print(\"  外れ値なし（安定した性能）\")\n",
        "\n",
        "    # 失敗タスク（スコア < 3.0）\n",
        "    failed = summary_df[summary_df['final_score'] < 3.0]\n",
        "    if len(failed) > 0:\n",
        "        print(f\"  失敗タスク（< 3.0）: {len(failed)}件\")\n",
        "\n",
        "    # 6. 改善ポテンシャル\n",
        "    print(\"\\n【改善ポテンシャル】\")\n",
        "    perfect_gap = 5.0 - mean_score\n",
        "    achievable_target = summary_df['final_score'].quantile(0.75)\n",
        "    improvement_potential = achievable_target - mean_score\n",
        "\n",
        "    print(f\"  理論的改善余地: {perfect_gap:.2f}ポイント\")\n",
        "    print(f\"  現実的改善目標: {achievable_target:.2f} (+{improvement_potential:.2f})\")\n",
        "\n",
        "    if available:\n",
        "        # 最も改善効果が高い項目\n",
        "        impacts = []\n",
        "        for c in available:\n",
        "            potential = (5.0 - summary_df[c].mean()) * (1.0 / len(available))\n",
        "            impacts.append((c, potential))\n",
        "        best_impact = max(impacts, key=lambda x: x[1])\n",
        "        print(f\"  最大改善効果: {best_impact[0]} (+{best_impact[1]:.2f}ポイント期待)\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "    # 7. 結果の保存\n",
        "    try:\n",
        "        # 保存先の決定\n",
        "        if 'pipeline' in locals() and hasattr(pipeline, 'run_manager'):\n",
        "            base_path = pipeline.run_manager.run_dir\n",
        "            run_id = pipeline.run_manager.run_id\n",
        "        else:\n",
        "            base_path = Path(\"./outputs/baseline\")\n",
        "            base_path.mkdir(parents=True, exist_ok=True)\n",
        "            run_id = \"baseline\"\n",
        "\n",
        "        # 詳細CSV\n",
        "        csv_file = base_path / \"evaluation_results.csv\"\n",
        "        summary_df.to_csv(csv_file, index=False)\n",
        "\n",
        "        # 分析サマリJSON\n",
        "        analysis = {\n",
        "            'run_id': run_id,\n",
        "            'timestamp': str(datetime.now()),\n",
        "            'performance': {\n",
        "                'mean': float(mean_score),\n",
        "                'std': float(std_score),\n",
        "                'ci_95': float(ci_95),\n",
        "                'median': float(summary_df['final_score'].median()),\n",
        "                'q1': float(summary_df['final_score'].quantile(0.25)),\n",
        "                'q3': float(summary_df['final_score'].quantile(0.75))\n",
        "            },\n",
        "            'criteria': {c: {\n",
        "                'mean': float(summary_df[c].mean()),\n",
        "                'std': float(summary_df[c].std())\n",
        "            } for c in available},\n",
        "            'summary': {\n",
        "                'num_tasks': len(summary_df),\n",
        "                'num_failed': len(failed),\n",
        "                'num_outliers': len(outliers),\n",
        "                'improvement_potential': float(improvement_potential)\n",
        "            }\n",
        "        }\n",
        "\n",
        "        json_file = base_path / \"analysis_summary.json\"\n",
        "        with open(json_file, 'w') as f:\n",
        "            json.dump(analysis, f, indent=2)\n",
        "\n",
        "        print(f\"💾 結果を保存しました:\")\n",
        "        print(f\"  - {csv_file}\")\n",
        "        print(f\"  - {json_file}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ 保存エラー: {e}\")\n",
        "\n",
        "    # Colab用の詳細表示\n",
        "    if IN_COLAB:\n",
        "        from IPython.display import display\n",
        "        print(\"\\n【スコア要約統計】\")\n",
        "        display(summary_df['final_score'].describe())\n",
        "\n",
        "else:\n",
        "    print(\"⚠️ データがありません。Cell 11を実行してください。\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N5veQyUuskRD",
        "outputId": "f382b8f1-5b2c-455d-a6f1-84d01925e2b7"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "📊 LA-Bench 2025 評価結果分析\n",
            "============================================================\n",
            "\n",
            "【全体パフォーマンス】\n",
            "  最終スコア: 2.17 ± 0.33 (95% CI)\n",
            "  中央値: 2.17\n",
            "  四分位範囲: [2.08, 2.25]\n",
            "  判定: ⚠️ 要改善\n",
            "\n",
            "【スコア分布】\n",
            "  [1]:   0 (  0.0%) \n",
            "  [2]:   2 (100.0%) ██████████████████████████████████████████████████\n",
            "  [3]:   0 (  0.0%) \n",
            "  [4]:   0 (  0.0%) \n",
            "  [5]:   0 (  0.0%) \n",
            "\n",
            "【評価項目分析】\n",
            "  強み（上位3項目）:\n",
            "    safety      : 4.50±0.71 ◆◆◆◆\n",
            "    completeness: 4.00±0.00 ◆◆◆◆\n",
            "    feasibility : 4.00±0.00 ◆◆◆◆\n",
            "  弱み（下位3項目）:\n",
            "    specificity : 3.50±0.71 ◇\n",
            "    consistency : 3.00±0.00 ◇◇\n",
            "    clarity     : 3.00±0.00 ◇◇\n",
            "  最優先改善項目: specificity (不安定かつ低スコア)\n",
            "\n",
            "【減点分析】\n",
            "  減点なし: 0 (0.0%)\n",
            "  減点あり: 2 (100.0%)\n",
            "  減点による平均スコア低下: -nan\n",
            "\n",
            "【要注意タスク】\n",
            "  外れ値なし（安定した性能）\n",
            "  失敗タスク（< 3.0）: 2件\n",
            "\n",
            "【改善ポテンシャル】\n",
            "  理論的改善余地: 2.83ポイント\n",
            "  現実的改善目標: 2.25 (+0.08)\n",
            "  最大改善効果: consistency (+0.33ポイント期待)\n",
            "\n",
            "============================================================\n",
            "💾 結果を保存しました:\n",
            "  - outputs/runs/20250810_093739_1729/evaluation_results.csv\n",
            "  - outputs/runs/20250810_093739_1729/analysis_summary.json\n",
            "\n",
            "【スコア要約統計】\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "count    2.000000\n",
              "mean     2.166667\n",
              "std      0.235702\n",
              "min      2.000000\n",
              "25%      2.083333\n",
              "50%      2.166667\n",
              "75%      2.250000\n",
              "max      2.333333\n",
              "Name: final_score, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>final_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.166667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.235702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2.083333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.166667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.333333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 13: 詳細な評価結果の表示\n",
        "#@title 13. 詳細な評価結果の表示 { display-mode: \"form\" }\n",
        "\n",
        "task_index = 0 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "if 'results' in locals() and results and task_index < len(results):\n",
        "    result = results[task_index]\n",
        "    eval_result = result['evaluation']\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(f\"📋 Task {result['task_id']}: 詳細評価結果\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(f\"\\n📝 実験指示:\")\n",
        "    print(f\"  {result['instruction']}\")\n",
        "\n",
        "    print(f\"\\n📊 総合評価:\")\n",
        "    print(f\"  最終スコア: {eval_result.final_score:.2f}/5.0\")\n",
        "    print(f\"  （減点前: {eval_result.raw_score:.2f}/5.0）\")\n",
        "\n",
        "    print(f\"\\n📈 評価項目別スコア:\")\n",
        "    for criterion in ['completeness', 'specificity', 'consistency',\n",
        "                     'safety', 'feasibility', 'clarity']:\n",
        "        score_obj = getattr(eval_result, criterion)\n",
        "        print(f\"  {criterion:12s}: {score_obj.score}/5 - {score_obj.reasoning[:50]}...\")\n",
        "\n",
        "    if eval_result.deductions:\n",
        "        print(f\"\\n⚠️ 減点項目:\")\n",
        "        for ded in eval_result.deductions:\n",
        "            print(f\"  - {ded.reason} (-{ded.points}点)\")\n",
        "            if ded.examples:\n",
        "                print(f\"    例: {ded.examples[0][:50]}...\")\n",
        "\n",
        "    print(f\"\\n💬 総合フィードバック:\")\n",
        "    print(f\"  {eval_result.feedback}\")\n",
        "\n",
        "    if eval_result.improvements:\n",
        "        print(f\"\\n💡 改善提案:\")\n",
        "        for imp in eval_result.improvements[:3]:  # 最初の3つ\n",
        "            print(f\"  - {imp}\")\n",
        "\n",
        "    print(f\"\\n🔬 生成された手順（{len(result['generated_steps'])}ステップ）:\")\n",
        "    for step in result['generated_steps'][:5]:  # 最初の5ステップ\n",
        "        print(f\"  {step['id']}. {step['text'][:80]}...\")\n",
        "    if len(result['generated_steps']) > 5:\n",
        "        print(f\"  ... 他 {len(result['generated_steps']) - 5} ステップ\")\n",
        "else:\n",
        "    print(\"⚠️ 表示するデータがありません\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23AuAcYoRhV7",
        "outputId": "8ad12c48-6d43-425d-9a66-e6be2b89310e"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "📋 Task 0002: 詳細評価結果\n",
            "============================================================\n",
            "\n",
            "📝 実験指示:\n",
            "  24ウェルプレートで細胞の培地交換を行ってください\n",
            "\n",
            "📊 総合評価:\n",
            "  最終スコア: 2.33/5.0\n",
            "  （減点前: 3.83/5.0）\n",
            "\n",
            "📈 評価項目別スコア:\n",
            "  completeness: 4/5 - PPE、BSC、滅菌ピペット、アスピレーター、温めた培地、廃棄手順、インキュベーター戻しまで一連の要...\n",
            "  specificity : 4/5 - 温度（37°C）、温め時間（15–30分）、添加量（1.0 mL/ウェル）、揺す回数（3–5回）など...\n",
            "  consistency : 3/5 - 手順全体は論理的だが、文中に繰り返し（例：\"DMEMDMEM\"、\"24ウェル24ウェル\"）があり読み...\n",
            "  safety      : 5/5 - PPE着用、BSC内作業、廃液の10%次亜塩素酸ナトリウムでの処理、作業面のエタノール拭き、汚染物の...\n",
            "  feasibility : 4/5 - 一般的な細胞培養ラボでそのまま実行可能な手順である。ただし、吸引やピペッティング時の細かな取り扱い指...\n",
            "  clarity     : 3/5 - 大部分はわかりやすいが、語句の重複（DMEMDMEM 等）やいくつかの曖昧な表現（「速やかに」「必要...\n",
            "\n",
            "⚠️ 減点項目:\n",
            "  - 不自然な日本語（語句の重複・繰り返し）: 例）\"DMEMDMEM\"、\"24ウェル24ウェル\" といった重複表現。 (-1.0点)\n",
            "  - 曖昧な表現（手順内の矛盾）: 例）ステップ7の「完全に除去する（残量は残さないが、ウェル底面に触れない）」は実務上の意味が曖昧。 (-0.5点)\n",
            "\n",
            "💬 総合フィードバック:\n",
            "  全体として培地交換の標準手順をよくカバーしており、安全面の配慮も十分で実用的です。ただし文書に繰り返しや矛盾が散見され、初心者がそのまま読むと実施時に迷う箇所があります。特に“完全に除去する”という表現の解釈（残量を残すのか否か）や、吸引位置・速度などの定量的指示の欠如を改善してください。また日本語の重複を修正すると読みやすくなります。\n",
            "\n",
            "💡 改善提案:\n",
            "  - 文書内の重複表現（例：\"DMEMDMEM\"、\"24ウェル24ウェル\"）を削除して自然な日本語に統一する。\n",
            "  - ステップ7の記述を明確化する。例：「ウェル底面に触れないように注意しつつ、上層の培地をほぼ完全に除去する（目安：残量 ≤ ~50 µL）」のように具体的量を示す。\n",
            "  - 吸引の具体的な取り扱いを追加する（先端をウェル側壁に沿って斜めに当てる、先端と細胞層の距離の目安、吸引速度の指示など）。\n",
            "\n",
            "🔬 生成された手順（14ステップ）:\n",
            "  1. 準備：実験着・手袋・保護眼鏡を着用する。作業は生物安全キャビネット（BSC、クリーンベンチ）内で行う。廃液用に10%次亜塩素酸ナトリウムを含む廃液容器を用意し、...\n",
            "  2. 機器の電源・温度設定：恒温槽（水浴）を37°Cに設定して電源を入れ、少なくとも15分前から温度が安定するように準備する。インキュベーター（37°C、5% CO2...\n",
            "  3. DMEM培地の準備：使用するDMEMDMEM培地（実験で用いる調整済みDMEM）を滅菌ボトルのまま恒温槽の37°C水浴に入れ、ラベル面が濡れないようにして約15...\n",
            "  4. 器具・消耗品の準備：BSC内に滅菌済み5 mL セロロジカルピペット（必要数）、ピペットエイド、滅菌P1000チップ（予備）、滅菌ピンセット、アルコール（70%...\n",
            "  5. 24ウェルプレート確認：インキュベーターのドアを最小限の開閉で扱い、インキュベーターから目的の24ウェル24ウェルプレートを取り出す。取り出す前に24ウェルプレ...\n",
            "  ... 他 9 ステップ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RHEkF9V4ymXG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}